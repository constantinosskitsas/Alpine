679
Created new folder: ./data3_/res/_679
set seed: 5
Making ./raw_data/dblp.txt graph...
Done ./raw_data/dblp.txt Peter...
Graph with 9916 nodes and 44808 edges
Size of subgraph: 9872
Reading subgraph at ./data3_/dblp/10/0/subgraph.txt
Reading alignment at ./data3_/dblp/10/0/nodes.txt
Making ./data3_/dblp/10/0/subgraph.txt graph...
Done ./data3_/dblp/10/0/subgraph.txt Peter...
Graph with 9872 nodes and 39561 edges
Regal
Filename: /home/konstantinos/Alpine/REGAL/regal.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   137   2370.1 MiB   2370.1 MiB           1   @profile
   138                                         def learn_representations(adj, REGAL_args):
   139   2370.2 MiB      0.1 MiB           1       graph = Graph(adj, node_attributes=REGAL_args['attributes'])
   140   2370.2 MiB      0.0 MiB           1       max_layer = REGAL_args['untillayer']
   141   2370.2 MiB      0.0 MiB           1       if REGAL_args['untillayer'] == 0:
   142                                                 max_layer = None
   143   2370.2 MiB      0.0 MiB           1       alpha = REGAL_args['alpha']
   144   2370.2 MiB      0.0 MiB           1       num_buckets = REGAL_args['buckets']  # BASE OF LOG FOR LOG SCALE
   145   2370.2 MiB      0.0 MiB           1       if num_buckets == 1:
   146                                                 num_buckets = None
   147   2370.2 MiB      0.0 MiB           2       rep_method = RepMethod(max_layer=max_layer,
   148   2370.2 MiB      0.0 MiB           1                              alpha=alpha,
   149   2370.2 MiB      0.0 MiB           1                              k=REGAL_args['k'],
   150   2370.2 MiB      0.0 MiB           1                              num_buckets=num_buckets,
   151   2370.2 MiB      0.0 MiB           1                              normalize=True,
   152   2370.2 MiB      0.0 MiB           1                              gammastruc=REGAL_args['gammastruc'],
   153   2370.2 MiB      0.0 MiB           1                              gammaattr=REGAL_args['gammaattr'])
   154   2370.2 MiB      0.0 MiB           1       if max_layer is None:
   155                                                 max_layer = 1000
   156   2587.6 MiB    217.3 MiB           1       representations = get_representations(graph, rep_method)
   157   2587.6 MiB      0.0 MiB           1       return representations


Filename: /home/konstantinos/Alpine/REGAL/regal.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    25   3306.3 MiB   3306.3 MiB           1   @profile
    26                                         def convertToPermHungarian2(M, n, m):
    27   3306.3 MiB      0.0 MiB           1       row_ind, col_ind = scipy.optimize.linear_sum_assignment(M, maximize=True)
    28                                             #P = torch.zeros((n,m), dtype = torch.float64)
    29   3306.3 MiB      0.0 MiB           1       P= np.zeros((n,m))
    30                                             #A = torch.tensor(nx.to_numpy_array(Gq), dtype = torch.float64)
    31   3306.3 MiB      0.0 MiB           1       ans = []
    32   3345.0 MiB      0.8 MiB        9873       for i in range(n):
    33   3345.0 MiB     37.4 MiB        9872           P[row_ind[i]][col_ind[i]] = 1
    34   3345.0 MiB      0.0 MiB        9872           if (row_ind[i] >= n) or (col_ind[i] >= m):
    35                                                     continue
    36   3345.0 MiB      0.6 MiB        9872           ans.append((row_ind[i], col_ind[i]))
    37   3345.0 MiB      0.0 MiB           1       return P, ans


Filename: /home/konstantinos/Alpine/REGAL/regal.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    25   3363.3 MiB   3363.3 MiB           1   @profile
    26                                         def convertToPermHungarian2(M, n, m):
    27   3363.3 MiB      0.0 MiB           1       row_ind, col_ind = scipy.optimize.linear_sum_assignment(M, maximize=True)
    28                                             #P = torch.zeros((n,m), dtype = torch.float64)
    29   3363.3 MiB      0.0 MiB           1       P= np.zeros((n,m))
    30                                             #A = torch.tensor(nx.to_numpy_array(Gq), dtype = torch.float64)
    31   3363.3 MiB      0.0 MiB           1       ans = []
    32   3402.8 MiB      1.0 MiB        9873       for i in range(n):
    33   3402.8 MiB     37.8 MiB        9872           P[row_ind[i]][col_ind[i]] = 1
    34   3402.8 MiB      0.0 MiB        9872           if (row_ind[i] >= n) or (col_ind[i] >= m):
    35                                                     continue
    36   3402.8 MiB      0.7 MiB        9872           ans.append((row_ind[i], col_ind[i]))
    37   3402.8 MiB      0.0 MiB           1       return P, ans


Filename: /home/konstantinos/Alpine/REGAL/regal.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    78    608.7 MiB    608.7 MiB           1   @profile
    79                                         def Regal(Gq,Gt):
    80    608.7 MiB      0.0 MiB           1       dummy=False
    81    608.7 MiB      0.0 MiB           1       args = {
    82    608.7 MiB      0.0 MiB           1       'attributes': None,
    83    608.7 MiB      0.0 MiB           1       'attrvals': 2,
    84    608.7 MiB      0.0 MiB           1       'dimensions': 128,  # useless
    85    608.7 MiB      0.0 MiB           1       'k': 10,            # d = klogn
    86    608.7 MiB      0.0 MiB           1       'untillayer': 2,    # k
    87    608.7 MiB      0.0 MiB           1       'alpha': 0.01,      # delta
    88    608.7 MiB      0.0 MiB           1       'gammastruc': 1.0,
    89    608.7 MiB      0.0 MiB           1       'gammaattr': 1.0,
    90    608.7 MiB      0.0 MiB           1       'numtop': 10,
    91    608.7 MiB      0.0 MiB           1       'buckets': 2
    92                                             }
    93                                             # adj = G_to_Adj(Src, Tar).A
    94    608.7 MiB      0.0 MiB           1       n1 = len(Gq.nodes())
    95    608.7 MiB      0.0 MiB           1       n2 = len(Gt.nodes())
    96    608.7 MiB      0.0 MiB           1       n = max(n1, n2)
    97    608.7 MiB      0.0 MiB           1       nmin= min(n1,n2)
    98    608.7 MiB      0.0 MiB           1       if (dummy):
    99                                                 for i in range(n1, n):
   100                                                     Gq.add_node(i)
   101                                                     Gq.add_edge(i,i)
   102                                                 for i in range(n2, n):
   103                                                     Gt.add_node(i)
   104                                                 
   105                                         
   106   1355.7 MiB    747.1 MiB           1       A = nx.to_numpy_array(Gq)
   107   2106.2 MiB    750.5 MiB           1       B = nx.to_numpy_array(Gt)
   108   2106.2 MiB      0.0 MiB           1       if dummy:
   109                                                 adg =G_to_Adj(A, B)
   110                                             else:
   111                                         
   112   2370.1 MiB    263.9 MiB           1           adj = G_to_Adj1(A, B)
   113                                         
   114                                             # global REGAL_args
   115                                             # REGAL_args = parse_args()
   116                                         
   117                                         
   118   2548.2 MiB    178.1 MiB           1       embed = learn_representations(adj, args)
   119   2548.2 MiB      0.0 MiB           1       if(dummy):
   120                                                 emb1, emb2 = get_embeddings(embed)
   121                                             else:
   122   2548.2 MiB      0.0 MiB           1           emb1, emb2 = get_embeddings1(embed,n1)
   123   3306.1 MiB    757.9 MiB           2       alignment_matrix, cost_matrix = get_embedding_similarities(
   124   2548.2 MiB      0.0 MiB           1           emb1, emb2, num_top=10)
   125   3306.3 MiB      0.2 MiB           1       cost_matrix=cost_matrix*-1
   126   3345.1 MiB     38.8 MiB           1       P2,_ = convertToPermHungarian2(cost_matrix, n1, n2)
   127                                         
   128   3363.3 MiB     18.2 MiB           1       forbnorm = LA.norm(A[:n1,:n1] - (P2@B@P2.T)[:n1,:n1], 'fro')**2
   129   3403.0 MiB     39.8 MiB           1       P_perm,ans = convertToPermHungarian2(cost_matrix, n1, n2)
   130   3403.0 MiB      0.0 MiB           1       list_of_nodes = []
   131   3403.0 MiB      0.0 MiB        9873       for el in ans: list_of_nodes.append(el[1])
   132   3403.0 MiB      0.0 MiB           1       return ans, list_of_nodes, forbnorm


----  Regal ----
----> Forb_norm: 141116.0
----> Accuracy: 0.028458498023715414
----> Spec_norm: 0
----> Time: 2335.7854793071747
----> Isomorphic: False






Filename: PartialTest.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    28    385.6 MiB    385.6 MiB           1   @profile
    29                                         def RunExp():
    30    385.6 MiB      0.0 MiB           1       plotall = False
    31                                         
    32    385.6 MiB      0.0 MiB           1       folderall = 'data3_'
    33                                         
    34                                         
    35    385.6 MiB      0.0 MiB           1       foldernames = [ 'arenas','netscience', 'multimanga', 'highschool', 'voles']
    36    385.6 MiB      0.0 MiB           1       n_G = [ 1133,379, 1004, 327, 712]
    37                                             #foldernames = [  'douban']
    38                                             #n_G = [  3906]
    39    385.6 MiB      0.0 MiB           1       foldernames = [ 'netscience']
    40    385.6 MiB      0.0 MiB           1       n_G = [ 379]
    41                                             #foldernames=["random/subgraph_DG_80","random/subgraph_DG_160","random/subgraph_DG_320","random/subgraph_DG_640","random/subgraph_DG_1280","random/subgraph_DG_2560","random/subgraph_DG_5120"]
    42                                             #foldernames1=["random/subgraph_QG_80","random/subgraph_QG_160","random/subgraph_DG_QG","random/subgraph_QG_640","random/subgraph_QG_1280","random/subgraph_QG_2560","random/subgraph_QG_5120"]
    43                                             #n_G = [ 80,160,320,640,1280,2560,5120]
    44                                             #foldernames=["random/subgraph_DG_5120"]
    45                                             #foldernames1=["random/subgraph_QG_5120"]
    46                                             #n_G = [5120]
    47                                             #foldernames = [ 'highschool']
    48                                             #n_G = [ 327]
    49                                             #foldernames = [  'highschool']
    50                                             #n_G = [ 327]
    51                                             #n_G = [575,5002,11586]
    52                                             #n_GQ = [453,4623,8325]
    53                                             #n_GT = [437,4483,7555]
    54                                         
    55                                             #foldernames = [ 'male','route','sp']
    56                                             #n_G = [575]
    57                                             #n_G=[5003]
    58                                             #foldernames = ['facebook']
    59                                             #9916
    60                                             #9871
    61    385.6 MiB      0.0 MiB           1       iters =1
    62    385.6 MiB      0.0 MiB          12       percs = [(i+1)/10 for i in range(0,9)]
    63    385.6 MiB      0.0 MiB           1       percs=[0.1]
    64                                             #tun=[1,2,3,4,5,6,7]
    65    385.6 MiB      0.0 MiB           1       tuns=["Alpine","Cone","SGWL","Alpine_Dummy","Grampa","Regal","Fugal","mcmc","GradP"]
    66    385.6 MiB      0.0 MiB           1       tun=[1,2,3,4,5,6,8,9,10]
    67    385.6 MiB      0.0 MiB           1       tuns=["Regal"]
    68    385.6 MiB      0.0 MiB           1       tun=[6]
    69                                             #tuns=["Alpine_Dummy","Grad","mcmc"]
    70                                         
    71                                         
    72                                             #tun = [1,8,10]
    73                                             #nL=["_Noise5","_Noise10","_Noise15","_Noise20","_Noise25"]
    74                                             #tuns=["Alpine"]
    75                                             #tun=[4,8]
    76                                         
    77                                             #tun = [1]
    78                                             #n_G = [4039]
    79                                             #n_GQ = [9872]
    80                                             #n_GT = [9872]
    81                                         
    82                                             #n_G = [1043]
    83                                             #n_GQ = [1000]
    84                                             #n_GT = [1000]
    85                                         
    86                                             #foldernames = ['sp']
    87    385.6 MiB      0.0 MiB           1       foldernames = [ 'dblp']
    88    385.6 MiB      0.0 MiB           1       n_G = [9916]
    89    960.0 MiB      0.0 MiB           2       def printR(name,forb_norm,accuracy,spec_norm,time_diff,isomorphic=False):
    90    960.0 MiB      0.0 MiB           1           print('---- ',name, '----')
    91    960.0 MiB      0.0 MiB           1           print('----> Forb_norm:', forb_norm)
    92    960.0 MiB      0.0 MiB           1           print('----> Accuracy:', accuracy)
    93    960.0 MiB      0.0 MiB           1           print('----> Spec_norm:', spec_norm)
    94    960.0 MiB      0.0 MiB           1           print('----> Time:', time_diff)
    95    960.0 MiB      0.0 MiB           1           print('----> Isomorphic:', isomorphic)
    96    960.0 MiB      0.0 MiB           1           print()     
    97                                         
    98    385.6 MiB      0.0 MiB           1       experimental_folder=f'./{folderall}/res/'
    99    385.8 MiB      0.1 MiB           1       new_id = generate_new_id(get_max_previous_id(experimental_folder))
   100    385.8 MiB      0.0 MiB           1       experimental_folder=f'./{folderall}/res/_{new_id}/'   
   101    385.8 MiB      0.0 MiB           1       DGS=0
   102    385.8 MiB      0.0 MiB           1       DGES=0
   103    385.8 MiB      0.0 MiB           1       QGS=0
   104    385.8 MiB      0.0 MiB           1       QGES=0
   105    385.8 MiB      0.0 MiB           1       PGS=0
   106    385.8 MiB      0.0 MiB           1       PGES=0         
   107    960.0 MiB      0.0 MiB           2       for k in range(0,len(foldernames)):
   108    406.8 MiB     21.1 MiB           1               G = read_real_graph(n = n_G[k], name_ = f'./raw_data/{foldernames[k]}.txt')
   109    406.8 MiB      0.0 MiB           1               print(G)
   110    406.8 MiB      0.0 MiB           1               DGS=G.number_of_nodes()
   111                                         
   112                                             # Get the number of edges
   113    406.8 MiB      0.0 MiB           1               DGES = G.number_of_edges()
   114                                                     
   115                                                     #perc=percs[0]
   116    960.0 MiB      0.0 MiB           2               for perc in percs: 
   117    960.0 MiB      0.0 MiB           2                   for ptun in range(len(tun)): 
   118    406.8 MiB      0.0 MiB           1                       folder = f'./{folderall}/{foldernames[k]}/{int(perc*100)}'
   119    406.8 MiB      0.0 MiB           1                       os.makedirs(f'{experimental_folder}{foldernames[k]}/{int(perc*100)}', exist_ok=True)
   120    406.8 MiB      0.0 MiB           1                       folder1=f'./{experimental_folder}/{foldernames[k]}/{int(perc*100)}'
   121    406.8 MiB      0.0 MiB           1                       file_A_results = open(f'{folder1}/SizeTest_results{tuns[ptun]}.txt', 'w')
   122    406.8 MiB      0.0 MiB           1                       file_A_results.write(f'DGS DGES QGS QGES PGS PGES forb_norm accuracy spec_norm time isomorphic \n')
   123                                                             
   124    406.8 MiB      0.0 MiB           1                       file_real_spectrum = open(f'{folder1}/real_Tspectrum{tuns[ptun]}.txt', 'w')
   125    406.8 MiB      0.0 MiB           1                       file_A_spectrum = open(f'{folder1}/A_Tspectrum{tuns[ptun]}.txt', 'w')
   126    406.8 MiB      0.0 MiB           1                       n_Q = int(perc*G.number_of_nodes())
   127                                                             #n_Q=n_GQ[k]#9872
   128    406.8 MiB      0.0 MiB           1                       n_Q = 9872 
   129    406.8 MiB      0.0 MiB           1                       print(f'Size of subgraph: {n_Q}')
   130    960.0 MiB      0.0 MiB           2                       for iter in range(iters):
   131    406.8 MiB      0.0 MiB           1                           folder_ = f'{folder}/{iter}'
   132    406.8 MiB      0.0 MiB           1                           folder1_ = f'{folder1}/{iter}'
   133                                                                 #folder_ = f'{folder}'
   134    406.8 MiB      0.0 MiB           1                           os.makedirs(f'{folder1_}', exist_ok=True)
   135    406.8 MiB      0.0 MiB           1                           file_subgraph = f'{folder_}/subgraph.txt'
   136    406.8 MiB      0.0 MiB           1                           file_nodes = f'{folder_}/nodes.txt'
   137                                                                 #file_subgraph = f'raw_data/random/subgraph_QG_{n_G[k]}.txt'
   138                                                                 #file_nodes = f'raw_data/random/nodes_QG_{n_G[k]}.txt'
   139    406.8 MiB      0.0 MiB           1                           Q_real = read_list(file_nodes)
   140    406.8 MiB      0.0 MiB           1                           print(f'Reading subgraph at {file_subgraph}')
   141    406.8 MiB      0.0 MiB           1                           print(f'Reading alignment at {file_nodes}')
   142    425.5 MiB     18.7 MiB           1                           G_Q= read_real_graph(n = n_Q, name_ = file_subgraph)
   143    577.4 MiB    151.9 MiB           1                           A = nx.adjacency_matrix(G_Q).todense()
   144    577.4 MiB      0.0 MiB           1                           print(G_Q)
   145                                                                 #print(Q_real)
   146    577.4 MiB      0.0 MiB           1                           QGS=G_Q.number_of_nodes()
   147    577.4 MiB      0.0 MiB           1                           QGES = G_Q.number_of_edges()
   148                                                                 #L = np.diag(np.array(np.sum(A, axis = 0)))
   149                                                                 #eigv_G_Q, _ = linalg.eig(L - A)
   150                                                                 #idx = eigv_G_Q.argsort()[::]   
   151                                                                 #eigv_G_Q = eigv_G_Q[idx]
   152                                                                 #for el in eigv_G_Q: file_real_spectrum.write(f'{el} ')
   153                                                                 #file_real_spectrum.write(f'\n')
   154    577.4 MiB      0.0 MiB           1                           start = time.time()
   155    577.4 MiB      0.0 MiB           1                           if(tun[ptun]==1):
   156                                                                     print("Alpine")
   157                                                                     _, list_of_nodes, forb_norm = Alpine(G_Q.copy(), G.copy(),mu=1,weight=2)
   158    577.4 MiB      0.0 MiB           1                           elif(tun[ptun]==2):
   159                                                                     print("Cone")
   160                                                                     _, list_of_nodes, forb_norm = coneGAM(G_Q.copy(), G.copy())
   161    577.4 MiB      0.0 MiB           1                           elif(tun[ptun]==3):
   162                                                                     print("SGWL")
   163                                                                     _, list_of_nodes, forb_norm = SGWLSA(G_Q.copy(), G.copy())
   164    577.4 MiB      0.0 MiB           1                           elif(tun[ptun]==4):
   165                                                                     print("Alpine_Dummy")
   166                                                                     _, list_of_nodes, forb_norm = align_new(G_Q.copy(), G.copy(),mu=1,weight=1)
   167    577.4 MiB      0.0 MiB           1                           elif(tun[ptun]==5):
   168                                                                     print("Grampa")
   169                                                                     _, list_of_nodes, forb_norm = Grampa(G_Q.copy(), G.copy())
   170    577.4 MiB      0.0 MiB           1                           elif(tun[ptun]==6):
   171    577.4 MiB      0.0 MiB           1                               print("Regal")
   172    821.5 MiB    244.1 MiB           1                               _, list_of_nodes, forb_norm = Regal(G_Q.copy(), G.copy())      
   173                                                                 elif(tun[ptun]==7):
   174                                                                     print("MDS")
   175                                                                     _, list_of_nodes, forb_norm = MDSGA(G_Q.copy(), G.copy())
   176                                                                 elif(tun[ptun]==8):
   177                                                                     print("fugal")
   178                                                                     _,list_of_nodes, forb_norm = Fugal(G_Q.copy(), G.copy())
   179                                                                 elif(tun[ptun]==9):
   180                                                                     print("mcmc")
   181                                                                     list_of_nodes, forb_norm = mcAlign(G_Q.copy(), G.copy(),Q_real)
   182                                                                 elif(tun[ptun]==10):
   183                                                                     print("GradAlignP")
   184                                                                     list_of_nodes, forb_norm = gradPMain(G_Q.copy(), G.copy())
   185                                                                 else:
   186                                                                     print("NO given algorithm ID")
   187                                                                     exit()
   188    821.5 MiB      0.0 MiB           1                           end = time.time()
   189    821.5 MiB      0.0 MiB           1                           subgraph = G.subgraph(list_of_nodes)
   190                                                                 
   191    821.5 MiB      0.0 MiB           1                           PGS=subgraph.number_of_nodes()
   192    821.5 MiB      0.0 MiB           1                           PGES = subgraph.number_of_edges()
   193    821.5 MiB      0.0 MiB           1                           isomorphic=False
   194    821.5 MiB      0.0 MiB           1                           if(forb_norm==0):
   195                                                                     isomorphic=True
   196    821.5 MiB      0.0 MiB           1                           time_diff = end - start
   197    821.5 MiB      0.0 MiB           1                           file_nodes_pred = open(f'{folder1_}/{tuns[ptun]}.txt','w')
   198    821.5 MiB      0.0 MiB        9873                           for node in list_of_nodes: file_nodes_pred.write(f'{node}\n')
   199    921.5 MiB    100.0 MiB           1                           A = nx.adjacency_matrix(nx.induced_subgraph(G, list_of_nodes)).todense()
   200    959.9 MiB     38.4 MiB           1                           L = np.diag(np.array(np.sum(A, axis = 0)))
   201                                         
   202                                         
   203                                                                 #   accuracy = np.sum(np.array(Q_real)==np.array(list_of_nodes))/len(Q_real)
   204    959.9 MiB      0.0 MiB           1                           accuracy = np.sum(np.array(Q_real)==np.array(list_of_nodes))/1265
   205                                                                 #len(Q_real)
   206    959.9 MiB      0.0 MiB           1                           spec_norm=0
   207    960.0 MiB      0.1 MiB           1                           file_A_results.write(f'{DGS} {DGES} {QGS} {QGES} {PGS} {PGES} {forb_norm} {accuracy} {spec_norm} {time_diff} {isomorphic}\n')
   208    960.0 MiB      0.0 MiB           1                           printR(tuns[ptun],forb_norm,accuracy,0,time_diff,isomorphic)            
   209    960.0 MiB      0.0 MiB           1                   print('\n')
   210    960.0 MiB      0.0 MiB           1               print('\n\n')


Filename: /home/konstantinos/Alpine/REGAL/xnetmf.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   200 2370.250 MiB 2370.250 MiB           1   @profile
   201                                         def get_representations(graph, rep_method, verbose=False):
   202                                             # Node identity extraction
   203 2542.812 MiB  172.562 MiB           1       feature_matrix = get_features(graph, rep_method, verbose)
   204                                         
   205                                             # Efficient similarity-based representation
   206                                             # Get landmark nodes
   207 2542.812 MiB    0.000 MiB           1       if rep_method.p is None:
   208 2542.812 MiB    0.000 MiB           2           rep_method.p = get_feature_dimensionality(
   209 2542.812 MiB    0.000 MiB           1               graph, rep_method, verbose=verbose)  # k*log(n), where k = 10
   210                                             elif rep_method.p > graph.N:
   211                                                 print("Warning: dimensionality greater than number of nodes. Reducing to n")
   212                                                 rep_method.p = graph.N
   213 2542.938 MiB    0.125 MiB           1       landmarks = get_sample_nodes(graph, rep_method, verbose=verbose)
   214                                         
   215                                             # Explicitly compute similarities of all nodes to these landmarks
   216 2542.938 MiB    0.000 MiB           1       before_computesim = time.time()
   217 2542.938 MiB    0.000 MiB           1       C = np.zeros((graph.N, rep_method.p))
   218 2564.613 MiB    0.000 MiB       19789       for node_index in range(graph.N):  # for each of N nodes
   219 2564.613 MiB    1.086 MiB     2829684           for landmark_index in range(rep_method.p):  # for each of p landmarks
   220                                                     # select the p-th landmark
   221 2564.613 MiB   13.855 MiB     5619792               C[node_index, landmark_index] = compute_similarity(graph,
   222 2564.613 MiB    1.066 MiB     2809896                                                                  rep_method,
   223 2564.613 MiB    1.281 MiB     2809896                                                                  feature_matrix[node_index],
   224 2564.613 MiB    1.488 MiB     2809896                                                                  feature_matrix[landmarks[landmark_index]],
   225 2564.613 MiB    1.879 MiB     2809896                                                                  graph.node_attributes,
   226 2564.613 MiB    1.020 MiB     2809896                                                                  (node_index, landmarks[landmark_index]))
   227                                         
   228 2564.613 MiB    0.000 MiB           1       before_computerep = time.time()
   229                                         
   230                                             # Compute Nystrom-based node embeddings
   231 2567.152 MiB    2.539 MiB           1       W_pinv = np.linalg.pinv(C[landmarks])
   232 2567.320 MiB    0.168 MiB           1       U, X, V = np.linalg.svd(W_pinv)
   233 2567.570 MiB    0.250 MiB           1       Wfac = np.dot(U, np.diag(np.sqrt(X)))
   234 2610.090 MiB   42.520 MiB           1       reprsn = np.dot(C, Wfac)
   235 2610.090 MiB    0.000 MiB           1       after_computerep = time.time()
   236 2610.090 MiB    0.000 MiB           1       if verbose:
   237                                                 print("computed representation in time: ",
   238                                                       after_computerep - before_computerep)
   239                                         
   240                                             # Post-processing step to normalize embeddings (true by default, for use with REGAL)
   241 2610.090 MiB    0.000 MiB           1       if rep_method.normalize:
   242 2610.090 MiB   -1.102 MiB           2           reprsn = reprsn / \
   243 2610.105 MiB    0.016 MiB           1               np.linalg.norm(reprsn, axis=1).reshape((reprsn.shape[0], 1))
   244 2609.004 MiB   -1.086 MiB           1       return reprsn


