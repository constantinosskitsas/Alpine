689
Created new folder: ./data3_/res/_689
set seed: 5
Making ./raw_data/dblp.txt graph...
Done ./raw_data/dblp.txt Peter...
Graph with 9916 nodes and 44808 edges
Size of subgraph: 9872
Reading subgraph at ./data3_/dblp/10/0/subgraph.txt
Reading alignment at ./data3_/dblp/10/0/nodes.txt
Making ./data3_/dblp/10/0/subgraph.txt graph...
Done ./data3_/dblp/10/0/subgraph.txt Peter...
Graph with 9872 nodes and 39561 edges
mcmc
Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    41   2106.9 MiB   2106.9 MiB           1   @profile
    42                                         def CenaExtractNodeFeature(g,layers):
    43   2424.0 MiB    317.1 MiB           1       g_degree_dict = cal_degree_dict(list(g.nodes()), g, layers)
    44   2424.0 MiB      0.0 MiB        9875       g_nodes = [i for i in range(len(g))]
    45   2424.0 MiB      0.0 MiB           1       N1 = len(g_nodes)
    46   2424.0 MiB      0.0 MiB           1       feature_mat = []
    47   2424.2 MiB      0.0 MiB           5       for layer in range(layers + 1):
    48   2424.2 MiB      0.0 MiB       39500           L_max = [np.log( np.max(g_degree_dict[layer][x]) + 1) for x in g_nodes]
    49   2424.2 MiB      0.2 MiB       39500           L_med= [np.log(np.median(g_degree_dict[layer][x]) + 1) for x in g_nodes]
    50   2424.2 MiB      0.0 MiB       39500           L_min=  [np.log( np.min(g_degree_dict[layer][x]) + 1) for x in g_nodes]
    51   2424.2 MiB      0.1 MiB       39500           L_75 = [np.log(np.percentile(g_degree_dict[layer][x], 75) + 1) for x in g_nodes]
    52   2424.2 MiB      0.0 MiB       39500           L_25 = [np.log( np.percentile(g_degree_dict[layer][x], 25) + 1) for x in g_nodes]
    53   2424.2 MiB      0.0 MiB           4           feature_mat.append(L_max)
    54   2424.2 MiB      0.0 MiB           4           feature_mat.append(L_min)
    55   2424.2 MiB      0.0 MiB           4           feature_mat.append(L_med)
    56   2424.2 MiB      0.0 MiB           4           feature_mat.append(L_75)
    57   2424.2 MiB      0.0 MiB           4           feature_mat.append(L_25)
    58   2424.2 MiB      0.0 MiB           1       feature_mat = np.array(feature_mat).reshape((-1,N1))
    59   2424.2 MiB      0.0 MiB           1       return feature_mat.transpose()


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    41   2414.0 MiB   2414.0 MiB           1   @profile
    42                                         def CenaExtractNodeFeature(g,layers):
    43   2526.1 MiB    112.1 MiB           1       g_degree_dict = cal_degree_dict(list(g.nodes()), g, layers)
    44   2526.1 MiB      0.0 MiB        9919       g_nodes = [i for i in range(len(g))]
    45   2526.1 MiB      0.0 MiB           1       N1 = len(g_nodes)
    46   2526.1 MiB      0.0 MiB           1       feature_mat = []
    47   2526.1 MiB      0.0 MiB           5       for layer in range(layers + 1):
    48   2526.1 MiB      0.0 MiB       39676           L_max = [np.log( np.max(g_degree_dict[layer][x]) + 1) for x in g_nodes]
    49   2526.1 MiB      0.0 MiB       39676           L_med= [np.log(np.median(g_degree_dict[layer][x]) + 1) for x in g_nodes]
    50   2526.1 MiB      0.0 MiB       39676           L_min=  [np.log( np.min(g_degree_dict[layer][x]) + 1) for x in g_nodes]
    51   2526.1 MiB      0.0 MiB       39676           L_75 = [np.log(np.percentile(g_degree_dict[layer][x], 75) + 1) for x in g_nodes]
    52   2526.1 MiB      0.0 MiB       39676           L_25 = [np.log( np.percentile(g_degree_dict[layer][x], 25) + 1) for x in g_nodes]
    53   2526.1 MiB      0.0 MiB           4           feature_mat.append(L_max)
    54   2526.1 MiB      0.0 MiB           4           feature_mat.append(L_min)
    55   2526.1 MiB      0.0 MiB           4           feature_mat.append(L_med)
    56   2526.1 MiB      0.0 MiB           4           feature_mat.append(L_75)
    57   2526.1 MiB      0.0 MiB           4           feature_mat.append(L_25)
    58   2526.1 MiB      0.0 MiB           1       feature_mat = np.array(feature_mat).reshape((-1,N1))
    59   2526.1 MiB      0.0 MiB           1       return feature_mat.transpose()


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   149   2511.0 MiB   2511.0 MiB           1   @profile
   150                                         def fast_select_train_nodes(g1,g2,e1,e2,train_ratio=0.01,distance_metric="euclidean",num_top=1,degree_threshold=6):
   151   2511.0 MiB      0.0 MiB           1       n = min(len(g1),len(g2))
   152   2511.0 MiB      0.0 MiB        9875       select_nodes1 = [node for node in g1.nodes() if g1.degree[node]>=degree_threshold]
   153   2511.0 MiB      0.0 MiB        9919       select_nodes2 = [node for node in g2.nodes() if g2.degree[node] >= degree_threshold]
   154                                         
   155   2511.0 MiB      0.0 MiB           1       index_dict1 = dict(zip(list(range(len(select_nodes1))),select_nodes1))
   156   2511.0 MiB      0.0 MiB           1       index_dict2 = dict(zip(list(range(len(select_nodes2))),select_nodes2))
   157                                         
   158   2511.0 MiB      0.0 MiB           1       new_e1 = e1[select_nodes1]
   159   2511.0 MiB      0.0 MiB           1       new_e2 = e2[select_nodes2]
   160                                             # print("rough select nodes from G1:{}".format(len(select_nodes1)))
   161                                             # print("rough select nodes from G2:{}".format(len(select_nodes2)))
   162                                         
   163   2511.0 MiB      0.1 MiB           1       kd_tree = KDTree(new_e2, metric=distance_metric)
   164                                         
   165   2511.0 MiB      0.0 MiB           1       dist, ind = kd_tree.query(new_e1, k=num_top)
   166   2511.0 MiB      0.0 MiB           1       dist_list = -dist[:, 0]
   167   2511.0 MiB      0.0 MiB           1       ind_list = ind[:, 0]
   168   2511.0 MiB      0.0 MiB           1       if int(train_ratio * n)>min(len(select_nodes1),len(select_nodes2)):
   169                                                 num = min(len(select_nodes1),len(select_nodes2))
   170                                             else:
   171   2511.0 MiB      0.0 MiB           1           num=int(train_ratio * n)
   172                                         
   173   2511.0 MiB      0.0 MiB           1       index_l = heapq.nlargest(num, range(len(dist_list)), dist_list.__getitem__)
   174   2511.0 MiB      0.0 MiB         397       train_data_dict = {index_dict1[i]: index_dict2[ind_list[i]] for i in index_l}
   175   2511.0 MiB      0.0 MiB           1       return train_data_dict


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    78   2511.1 MiB   2511.1 MiB           1   @profile
    79                                         def align_embedding(g1,g2 ,nodes1 ,nodes2,K_nei,r_rate,e1=None,e2=None):
    80   3254.6 MiB    743.5 MiB           1       adj1 = nx.to_numpy_array(g1,nodelist=list(range(len(g1))))
    81   4004.8 MiB    750.2 MiB           1       adj2 = nx.to_numpy_array(g2, nodelist=list(range(len(g2))))
    82   4004.8 MiB      0.0 MiB           1       D1 = np.sum(adj1,axis=0)
    83   4004.8 MiB      0.0 MiB           1       D2 = np.sum(adj2,axis=0)
    84   4004.8 MiB      0.0 MiB           1       dim=128
    85   4004.8 MiB      0.0 MiB           1       if(len(g1)<dim):
    86                                                 dim=len(g1)-1
    87   4004.8 MiB      0.0 MiB           1       if(len(g2)<dim):
    88                                                 dim=len(g2)-1
    89                                             #path1 = r"dataset/{}/Embedding_G1_{}.npy".format(dataname,str(r_rate))
    90                                             #path2 = r"dataset/{}/Embedding_G2_{}.npy".format(dataname, str(r_rate))
    91                                         
    92   4004.8 MiB      0.0 MiB           1       if e1 is None:
    93                                                 if False:#os.path.exists(path1):
    94                                                     e1 = np.load(path1)
    95                                                     e2 = np.load(path2)
    96                                                 else:
    97   4054.9 MiB     50.1 MiB           1               e1 = netmf(sps.csr_matrix(adj1),dim)
    98   4199.8 MiB    144.9 MiB           1               e2 = netmf(sps.csr_matrix(adj2),dim)
    99                                         
   100                                         
   101                                         
   102   4199.8 MiB      0.1 MiB           1       obj = e1[nodes1].T @  e2[nodes2]
   103   4199.8 MiB      0.0 MiB           1       e1_star = e1
   104   4199.8 MiB      0.0 MiB           1       e2_star = e2
   105                                         
   106   4199.8 MiB      0.0 MiB           1       combined_e1 = [e1]
   107   4199.8 MiB      0.0 MiB           1       combined_e2 = [e2]
   108                                         
   109   4199.9 MiB      0.0 MiB           1       tmp1 = sparse.csr_matrix(np.diag(1 / D1))@sparse.csr_matrix(adj1)
   110   4199.9 MiB      0.0 MiB           1       tmp2 = sparse.csr_matrix(np.diag(1 / D2))@sparse.csr_matrix(adj2)
   111                                         
   112   4199.9 MiB      0.0 MiB           1       s = time()
   113   4286.9 MiB      0.0 MiB           8       for i in range(K_nei):
   114   4277.2 MiB     38.4 MiB           7           e1_star = tmp1 @ e1_star
   115   4286.9 MiB     48.6 MiB           7           e2_star = tmp2 @ e2_star
   116   4286.9 MiB      0.0 MiB           7           combined_e1.append(e1_star)
   117   4286.9 MiB      0.0 MiB           7           combined_e2.append(e2_star)
   118   4286.9 MiB      0.0 MiB           7           obj += e1_star[nodes1].T @  e2_star[nodes2]
   119   4286.9 MiB      0.0 MiB           1       e = time()
   120                                         
   121                                         
   122   4286.9 MiB      0.0 MiB           1       obj = obj/K_nei
   123   4287.3 MiB      0.4 MiB           1       u, _, v = np.linalg.svd(obj)
   124   4287.3 MiB      0.0 MiB           1       R = u @ v
   125   4301.1 MiB     13.7 MiB           1       trans_e1 = e1 @ R
   126                                         
   127   4394.3 MiB     93.3 MiB          11       trans_combined_e1 = np.concatenate([item@ R for item in combined_e1],axis=-1)
   128   4471.8 MiB     77.5 MiB           1       combined_e2 = np.concatenate(combined_e2, axis=-1)
   129                                         
   130   4471.8 MiB      0.0 MiB           1       return trans_e1, e2, trans_combined_e1,combined_e2


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   132   2977.8 MiB   2977.8 MiB           1   @profile
   133                                         def select_train_nodes(e1,e2,train_ratio=0.01,distance_metric="euclidean",num_top=1):
   134                                             ## 稀疏矩阵对齐
   135   2977.8 MiB      0.0 MiB           1       n_nodes = e1.shape[0]
   136                                         
   137   2977.8 MiB      0.0 MiB           1       kd_tree = KDTree(e2, metric=distance_metric)
   138                                         
   139   2977.8 MiB      0.0 MiB           1       dist, ind = kd_tree.query(e1, k=num_top)
   140   2977.8 MiB      0.0 MiB           1       dist_list = -dist[:,0]
   141   2977.8 MiB      0.0 MiB           1       ind_list = ind[:,0]
   142                                         
   143   2926.1 MiB    -51.8 MiB           1       index_l = heapq.nlargest(int(train_ratio*n_nodes), range(len(dist_list)), dist_list.__getitem__)
   144   2926.1 MiB      0.0 MiB        4939       train_data_dict = {i: ind_list[i] for i in index_l}
   145                                         
   146                                         
   147   2926.1 MiB      0.0 MiB           1       return train_data_dict


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    78   2926.1 MiB   2926.1 MiB           1   @profile
    79                                         def align_embedding(g1,g2 ,nodes1 ,nodes2,K_nei,r_rate,e1=None,e2=None):
    80   3669.6 MiB    743.5 MiB           1       adj1 = nx.to_numpy_array(g1,nodelist=list(range(len(g1))))
    81   4419.8 MiB    750.2 MiB           1       adj2 = nx.to_numpy_array(g2, nodelist=list(range(len(g2))))
    82   4419.8 MiB      0.0 MiB           1       D1 = np.sum(adj1,axis=0)
    83   4419.8 MiB      0.0 MiB           1       D2 = np.sum(adj2,axis=0)
    84   4419.8 MiB      0.0 MiB           1       dim=128
    85   4419.8 MiB      0.0 MiB           1       if(len(g1)<dim):
    86                                                 dim=len(g1)-1
    87   4419.8 MiB      0.0 MiB           1       if(len(g2)<dim):
    88                                                 dim=len(g2)-1
    89                                             #path1 = r"dataset/{}/Embedding_G1_{}.npy".format(dataname,str(r_rate))
    90                                             #path2 = r"dataset/{}/Embedding_G2_{}.npy".format(dataname, str(r_rate))
    91                                         
    92   4419.8 MiB      0.0 MiB           1       if e1 is None:
    93                                                 if False:#os.path.exists(path1):
    94                                                     e1 = np.load(path1)
    95                                                     e2 = np.load(path2)
    96                                                 else:
    97                                                     e1 = netmf(sps.csr_matrix(adj1),dim)
    98                                                     e2 = netmf(sps.csr_matrix(adj2),dim)
    99                                         
   100                                         
   101                                         
   102   4419.8 MiB      0.0 MiB           1       obj = e1[nodes1].T @  e2[nodes2]
   103   4419.8 MiB      0.0 MiB           1       e1_star = e1
   104   4419.8 MiB      0.0 MiB           1       e2_star = e2
   105                                         
   106   4419.8 MiB      0.0 MiB           1       combined_e1 = [e1]
   107   4419.8 MiB      0.0 MiB           1       combined_e2 = [e2]
   108                                         
   109   4419.8 MiB      0.0 MiB           1       tmp1 = sparse.csr_matrix(np.diag(1 / D1))@sparse.csr_matrix(adj1)
   110   4419.8 MiB      0.0 MiB           1       tmp2 = sparse.csr_matrix(np.diag(1 / D2))@sparse.csr_matrix(adj2)
   111                                         
   112   4419.8 MiB      0.0 MiB           1       s = time()
   113   4419.8 MiB      0.0 MiB           8       for i in range(K_nei):
   114   4419.8 MiB      0.0 MiB           7           e1_star = tmp1 @ e1_star
   115   4419.8 MiB      0.0 MiB           7           e2_star = tmp2 @ e2_star
   116   4419.8 MiB      0.0 MiB           7           combined_e1.append(e1_star)
   117   4419.8 MiB      0.0 MiB           7           combined_e2.append(e2_star)
   118   4419.8 MiB      0.0 MiB           7           obj += e1_star[nodes1].T @  e2_star[nodes2]
   119   4419.8 MiB      0.0 MiB           1       e = time()
   120                                         
   121                                         
   122   4419.8 MiB      0.0 MiB           1       obj = obj/K_nei
   123   4419.8 MiB      0.0 MiB           1       u, _, v = np.linalg.svd(obj)
   124   4419.8 MiB      0.0 MiB           1       R = u @ v
   125   4419.8 MiB      0.0 MiB           1       trans_e1 = e1 @ R
   126                                         
   127   4497.1 MiB     77.3 MiB          11       trans_combined_e1 = np.concatenate([item@ R for item in combined_e1],axis=-1)
   128   4497.2 MiB      0.1 MiB           1       combined_e2 = np.concatenate(combined_e2, axis=-1)
   129                                         
   130   4497.2 MiB      0.0 MiB           1       return trans_e1, e2, trans_combined_e1,combined_e2


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   132   2848.9 MiB   2848.9 MiB           1   @profile
   133                                         def select_train_nodes(e1,e2,train_ratio=0.01,distance_metric="euclidean",num_top=1):
   134                                             ## 稀疏矩阵对齐
   135   2848.9 MiB      0.0 MiB           1       n_nodes = e1.shape[0]
   136                                         
   137   2848.9 MiB      0.0 MiB           1       kd_tree = KDTree(e2, metric=distance_metric)
   138                                         
   139   2848.9 MiB      0.0 MiB           1       dist, ind = kd_tree.query(e1, k=num_top)
   140   2848.9 MiB      0.0 MiB           1       dist_list = -dist[:,0]
   141   2848.9 MiB      0.0 MiB           1       ind_list = ind[:,0]
   142                                         
   143   2848.9 MiB      0.0 MiB           1       index_l = heapq.nlargest(int(train_ratio*n_nodes), range(len(dist_list)), dist_list.__getitem__)
   144   2848.9 MiB      0.0 MiB        4939       train_data_dict = {i: ind_list[i] for i in index_l}
   145                                         
   146                                         
   147   2848.9 MiB      0.0 MiB           1       return train_data_dict


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    78   2848.9 MiB   2848.9 MiB           1   @profile
    79                                         def align_embedding(g1,g2 ,nodes1 ,nodes2,K_nei,r_rate,e1=None,e2=None):
    80   3592.4 MiB    743.5 MiB           1       adj1 = nx.to_numpy_array(g1,nodelist=list(range(len(g1))))
    81   4342.6 MiB    750.2 MiB           1       adj2 = nx.to_numpy_array(g2, nodelist=list(range(len(g2))))
    82   4342.6 MiB      0.0 MiB           1       D1 = np.sum(adj1,axis=0)
    83   4342.6 MiB      0.0 MiB           1       D2 = np.sum(adj2,axis=0)
    84   4342.6 MiB      0.0 MiB           1       dim=128
    85   4342.6 MiB      0.0 MiB           1       if(len(g1)<dim):
    86                                                 dim=len(g1)-1
    87   4342.6 MiB      0.0 MiB           1       if(len(g2)<dim):
    88                                                 dim=len(g2)-1
    89                                             #path1 = r"dataset/{}/Embedding_G1_{}.npy".format(dataname,str(r_rate))
    90                                             #path2 = r"dataset/{}/Embedding_G2_{}.npy".format(dataname, str(r_rate))
    91                                         
    92   4342.6 MiB      0.0 MiB           1       if e1 is None:
    93                                                 if False:#os.path.exists(path1):
    94                                                     e1 = np.load(path1)
    95                                                     e2 = np.load(path2)
    96                                                 else:
    97                                                     e1 = netmf(sps.csr_matrix(adj1),dim)
    98                                                     e2 = netmf(sps.csr_matrix(adj2),dim)
    99                                         
   100                                         
   101                                         
   102   4342.6 MiB      0.0 MiB           1       obj = e1[nodes1].T @  e2[nodes2]
   103   4342.6 MiB      0.0 MiB           1       e1_star = e1
   104   4342.6 MiB      0.0 MiB           1       e2_star = e2
   105                                         
   106   4342.6 MiB      0.0 MiB           1       combined_e1 = [e1]
   107   4342.6 MiB      0.0 MiB           1       combined_e2 = [e2]
   108                                         
   109   4342.6 MiB      0.0 MiB           1       tmp1 = sparse.csr_matrix(np.diag(1 / D1))@sparse.csr_matrix(adj1)
   110   4342.6 MiB      0.0 MiB           1       tmp2 = sparse.csr_matrix(np.diag(1 / D2))@sparse.csr_matrix(adj2)
   111                                         
   112   4342.6 MiB      0.0 MiB           1       s = time()
   113   4342.6 MiB      0.0 MiB           8       for i in range(K_nei):
   114   4342.6 MiB      0.0 MiB           7           e1_star = tmp1 @ e1_star
   115   4342.6 MiB      0.0 MiB           7           e2_star = tmp2 @ e2_star
   116   4342.6 MiB      0.0 MiB           7           combined_e1.append(e1_star)
   117   4342.6 MiB      0.0 MiB           7           combined_e2.append(e2_star)
   118   4342.6 MiB      0.0 MiB           7           obj += e1_star[nodes1].T @  e2_star[nodes2]
   119   4342.6 MiB      0.0 MiB           1       e = time()
   120                                         
   121                                         
   122   4342.6 MiB      0.0 MiB           1       obj = obj/K_nei
   123   4342.6 MiB      0.0 MiB           1       u, _, v = np.linalg.svd(obj)
   124   4342.6 MiB      0.0 MiB           1       R = u @ v
   125   4342.6 MiB      0.0 MiB           1       trans_e1 = e1 @ R
   126                                         
   127   4399.9 MiB     57.3 MiB          11       trans_combined_e1 = np.concatenate([item@ R for item in combined_e1],axis=-1)
   128   4477.3 MiB     77.5 MiB           1       combined_e2 = np.concatenate(combined_e2, axis=-1)
   129                                         
   130   4477.3 MiB      0.0 MiB           1       return trans_e1, e2, trans_combined_e1,combined_e2


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   132   2906.5 MiB   2906.5 MiB           1   @profile
   133                                         def select_train_nodes(e1,e2,train_ratio=0.01,distance_metric="euclidean",num_top=1):
   134                                             ## 稀疏矩阵对齐
   135   2906.5 MiB      0.0 MiB           1       n_nodes = e1.shape[0]
   136                                         
   137   2906.5 MiB      0.0 MiB           1       kd_tree = KDTree(e2, metric=distance_metric)
   138                                         
   139   2906.5 MiB      0.0 MiB           1       dist, ind = kd_tree.query(e1, k=num_top)
   140   2906.5 MiB      0.0 MiB           1       dist_list = -dist[:,0]
   141   2906.5 MiB      0.0 MiB           1       ind_list = ind[:,0]
   142                                         
   143   2906.5 MiB      0.0 MiB           1       index_l = heapq.nlargest(int(train_ratio*n_nodes), range(len(dist_list)), dist_list.__getitem__)
   144   2906.5 MiB      0.0 MiB        4939       train_data_dict = {i: ind_list[i] for i in index_l}
   145                                         
   146                                         
   147   2906.5 MiB      0.0 MiB           1       return train_data_dict


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    78   2906.5 MiB   2906.5 MiB           1   @profile
    79                                         def align_embedding(g1,g2 ,nodes1 ,nodes2,K_nei,r_rate,e1=None,e2=None):
    80   3650.0 MiB    743.5 MiB           1       adj1 = nx.to_numpy_array(g1,nodelist=list(range(len(g1))))
    81   4400.2 MiB    750.2 MiB           1       adj2 = nx.to_numpy_array(g2, nodelist=list(range(len(g2))))
    82   4400.2 MiB      0.0 MiB           1       D1 = np.sum(adj1,axis=0)
    83   4400.2 MiB      0.0 MiB           1       D2 = np.sum(adj2,axis=0)
    84   4400.2 MiB      0.0 MiB           1       dim=128
    85   4400.2 MiB      0.0 MiB           1       if(len(g1)<dim):
    86                                                 dim=len(g1)-1
    87   4400.2 MiB      0.0 MiB           1       if(len(g2)<dim):
    88                                                 dim=len(g2)-1
    89                                             #path1 = r"dataset/{}/Embedding_G1_{}.npy".format(dataname,str(r_rate))
    90                                             #path2 = r"dataset/{}/Embedding_G2_{}.npy".format(dataname, str(r_rate))
    91                                         
    92   4400.2 MiB      0.0 MiB           1       if e1 is None:
    93                                                 if False:#os.path.exists(path1):
    94                                                     e1 = np.load(path1)
    95                                                     e2 = np.load(path2)
    96                                                 else:
    97                                                     e1 = netmf(sps.csr_matrix(adj1),dim)
    98                                                     e2 = netmf(sps.csr_matrix(adj2),dim)
    99                                         
   100                                         
   101                                         
   102   4400.2 MiB      0.0 MiB           1       obj = e1[nodes1].T @  e2[nodes2]
   103   4400.2 MiB      0.0 MiB           1       e1_star = e1
   104   4400.2 MiB      0.0 MiB           1       e2_star = e2
   105                                         
   106   4400.2 MiB      0.0 MiB           1       combined_e1 = [e1]
   107   4400.2 MiB      0.0 MiB           1       combined_e2 = [e2]
   108                                         
   109   4400.2 MiB      0.0 MiB           1       tmp1 = sparse.csr_matrix(np.diag(1 / D1))@sparse.csr_matrix(adj1)
   110   4400.2 MiB      0.0 MiB           1       tmp2 = sparse.csr_matrix(np.diag(1 / D2))@sparse.csr_matrix(adj2)
   111                                         
   112   4400.2 MiB      0.0 MiB           1       s = time()
   113   4400.2 MiB      0.0 MiB           8       for i in range(K_nei):
   114   4400.2 MiB      0.0 MiB           7           e1_star = tmp1 @ e1_star
   115   4400.2 MiB      0.0 MiB           7           e2_star = tmp2 @ e2_star
   116   4400.2 MiB      0.0 MiB           7           combined_e1.append(e1_star)
   117   4400.2 MiB      0.0 MiB           7           combined_e2.append(e2_star)
   118   4400.2 MiB      0.0 MiB           7           obj += e1_star[nodes1].T @  e2_star[nodes2]
   119   4400.2 MiB      0.0 MiB           1       e = time()
   120                                         
   121                                         
   122   4400.2 MiB      0.0 MiB           1       obj = obj/K_nei
   123   4400.2 MiB      0.0 MiB           1       u, _, v = np.linalg.svd(obj)
   124   4400.2 MiB      0.0 MiB           1       R = u @ v
   125   4400.3 MiB      0.0 MiB           1       trans_e1 = e1 @ R
   126                                         
   127   4477.3 MiB     77.1 MiB          11       trans_combined_e1 = np.concatenate([item@ R for item in combined_e1],axis=-1)
   128   4477.5 MiB      0.1 MiB           1       combined_e2 = np.concatenate(combined_e2, axis=-1)
   129                                         
   130   4477.5 MiB      0.0 MiB           1       return trans_e1, e2, trans_combined_e1,combined_e2


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   132   2829.2 MiB   2829.2 MiB           1   @profile
   133                                         def select_train_nodes(e1,e2,train_ratio=0.01,distance_metric="euclidean",num_top=1):
   134                                             ## 稀疏矩阵对齐
   135   2829.2 MiB      0.0 MiB           1       n_nodes = e1.shape[0]
   136                                         
   137   2829.2 MiB      0.0 MiB           1       kd_tree = KDTree(e2, metric=distance_metric)
   138                                         
   139   2829.2 MiB      0.0 MiB           1       dist, ind = kd_tree.query(e1, k=num_top)
   140   2829.2 MiB      0.0 MiB           1       dist_list = -dist[:,0]
   141   2829.2 MiB      0.0 MiB           1       ind_list = ind[:,0]
   142                                         
   143   2829.2 MiB      0.0 MiB           1       index_l = heapq.nlargest(int(train_ratio*n_nodes), range(len(dist_list)), dist_list.__getitem__)
   144   2829.2 MiB      0.0 MiB        4939       train_data_dict = {i: ind_list[i] for i in index_l}
   145                                         
   146                                         
   147   2829.2 MiB      0.0 MiB           1       return train_data_dict


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    78   2829.2 MiB   2829.2 MiB           1   @profile
    79                                         def align_embedding(g1,g2 ,nodes1 ,nodes2,K_nei,r_rate,e1=None,e2=None):
    80   3572.7 MiB    743.5 MiB           1       adj1 = nx.to_numpy_array(g1,nodelist=list(range(len(g1))))
    81   4322.9 MiB    750.2 MiB           1       adj2 = nx.to_numpy_array(g2, nodelist=list(range(len(g2))))
    82   4322.9 MiB      0.0 MiB           1       D1 = np.sum(adj1,axis=0)
    83   4322.9 MiB      0.0 MiB           1       D2 = np.sum(adj2,axis=0)
    84   4322.9 MiB      0.0 MiB           1       dim=128
    85   4322.9 MiB      0.0 MiB           1       if(len(g1)<dim):
    86                                                 dim=len(g1)-1
    87   4322.9 MiB      0.0 MiB           1       if(len(g2)<dim):
    88                                                 dim=len(g2)-1
    89                                             #path1 = r"dataset/{}/Embedding_G1_{}.npy".format(dataname,str(r_rate))
    90                                             #path2 = r"dataset/{}/Embedding_G2_{}.npy".format(dataname, str(r_rate))
    91                                         
    92   4322.9 MiB      0.0 MiB           1       if e1 is None:
    93                                                 if False:#os.path.exists(path1):
    94                                                     e1 = np.load(path1)
    95                                                     e2 = np.load(path2)
    96                                                 else:
    97                                                     e1 = netmf(sps.csr_matrix(adj1),dim)
    98                                                     e2 = netmf(sps.csr_matrix(adj2),dim)
    99                                         
   100                                         
   101                                         
   102   4322.9 MiB      0.0 MiB           1       obj = e1[nodes1].T @  e2[nodes2]
   103   4322.9 MiB      0.0 MiB           1       e1_star = e1
   104   4322.9 MiB      0.0 MiB           1       e2_star = e2
   105                                         
   106   4322.9 MiB      0.0 MiB           1       combined_e1 = [e1]
   107   4322.9 MiB      0.0 MiB           1       combined_e2 = [e2]
   108                                         
   109   4322.9 MiB      0.0 MiB           1       tmp1 = sparse.csr_matrix(np.diag(1 / D1))@sparse.csr_matrix(adj1)
   110   4322.9 MiB      0.0 MiB           1       tmp2 = sparse.csr_matrix(np.diag(1 / D2))@sparse.csr_matrix(adj2)
   111                                         
   112   4322.9 MiB      0.0 MiB           1       s = time()
   113   4322.9 MiB      0.0 MiB           8       for i in range(K_nei):
   114   4322.9 MiB      0.0 MiB           7           e1_star = tmp1 @ e1_star
   115   4322.9 MiB      0.0 MiB           7           e2_star = tmp2 @ e2_star
   116   4322.9 MiB      0.0 MiB           7           combined_e1.append(e1_star)
   117   4322.9 MiB      0.0 MiB           7           combined_e2.append(e2_star)
   118   4322.9 MiB      0.0 MiB           7           obj += e1_star[nodes1].T @  e2_star[nodes2]
   119   4322.9 MiB      0.0 MiB           1       e = time()
   120                                         
   121                                         
   122   4322.9 MiB      0.0 MiB           1       obj = obj/K_nei
   123   4322.9 MiB      0.0 MiB           1       u, _, v = np.linalg.svd(obj)
   124   4322.9 MiB      0.0 MiB           1       R = u @ v
   125   4322.9 MiB      0.0 MiB           1       trans_e1 = e1 @ R
   126                                         
   127   4399.9 MiB     77.0 MiB          11       trans_combined_e1 = np.concatenate([item@ R for item in combined_e1],axis=-1)
   128   4477.3 MiB     77.5 MiB           1       combined_e2 = np.concatenate(combined_e2, axis=-1)
   129                                         
   130   4477.3 MiB      0.0 MiB           1       return trans_e1, e2, trans_combined_e1,combined_e2


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   132   2906.5 MiB   2906.5 MiB           1   @profile
   133                                         def select_train_nodes(e1,e2,train_ratio=0.01,distance_metric="euclidean",num_top=1):
   134                                             ## 稀疏矩阵对齐
   135   2906.5 MiB      0.0 MiB           1       n_nodes = e1.shape[0]
   136                                         
   137   2906.5 MiB      0.0 MiB           1       kd_tree = KDTree(e2, metric=distance_metric)
   138                                         
   139   2906.5 MiB      0.0 MiB           1       dist, ind = kd_tree.query(e1, k=num_top)
   140   2906.5 MiB      0.0 MiB           1       dist_list = -dist[:,0]
   141   2906.5 MiB      0.0 MiB           1       ind_list = ind[:,0]
   142                                         
   143   2906.5 MiB      0.0 MiB           1       index_l = heapq.nlargest(int(train_ratio*n_nodes), range(len(dist_list)), dist_list.__getitem__)
   144   2906.5 MiB      0.0 MiB        4939       train_data_dict = {i: ind_list[i] for i in index_l}
   145                                         
   146                                         
   147   2906.5 MiB      0.0 MiB           1       return train_data_dict


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    78   2906.5 MiB   2906.5 MiB           1   @profile
    79                                         def align_embedding(g1,g2 ,nodes1 ,nodes2,K_nei,r_rate,e1=None,e2=None):
    80   3650.0 MiB    743.5 MiB           1       adj1 = nx.to_numpy_array(g1,nodelist=list(range(len(g1))))
    81   4400.2 MiB    750.2 MiB           1       adj2 = nx.to_numpy_array(g2, nodelist=list(range(len(g2))))
    82   4400.2 MiB      0.0 MiB           1       D1 = np.sum(adj1,axis=0)
    83   4400.2 MiB      0.0 MiB           1       D2 = np.sum(adj2,axis=0)
    84   4400.2 MiB      0.0 MiB           1       dim=128
    85   4400.2 MiB      0.0 MiB           1       if(len(g1)<dim):
    86                                                 dim=len(g1)-1
    87   4400.2 MiB      0.0 MiB           1       if(len(g2)<dim):
    88                                                 dim=len(g2)-1
    89                                             #path1 = r"dataset/{}/Embedding_G1_{}.npy".format(dataname,str(r_rate))
    90                                             #path2 = r"dataset/{}/Embedding_G2_{}.npy".format(dataname, str(r_rate))
    91                                         
    92   4400.2 MiB      0.0 MiB           1       if e1 is None:
    93                                                 if False:#os.path.exists(path1):
    94                                                     e1 = np.load(path1)
    95                                                     e2 = np.load(path2)
    96                                                 else:
    97                                                     e1 = netmf(sps.csr_matrix(adj1),dim)
    98                                                     e2 = netmf(sps.csr_matrix(adj2),dim)
    99                                         
   100                                         
   101                                         
   102   4400.2 MiB      0.0 MiB           1       obj = e1[nodes1].T @  e2[nodes2]
   103   4400.2 MiB      0.0 MiB           1       e1_star = e1
   104   4400.2 MiB      0.0 MiB           1       e2_star = e2
   105                                         
   106   4400.2 MiB      0.0 MiB           1       combined_e1 = [e1]
   107   4400.2 MiB      0.0 MiB           1       combined_e2 = [e2]
   108                                         
   109   4400.2 MiB      0.0 MiB           1       tmp1 = sparse.csr_matrix(np.diag(1 / D1))@sparse.csr_matrix(adj1)
   110   4400.2 MiB      0.0 MiB           1       tmp2 = sparse.csr_matrix(np.diag(1 / D2))@sparse.csr_matrix(adj2)
   111                                         
   112   4400.2 MiB      0.0 MiB           1       s = time()
   113   4400.2 MiB      0.0 MiB           8       for i in range(K_nei):
   114   4400.2 MiB      0.0 MiB           7           e1_star = tmp1 @ e1_star
   115   4400.2 MiB      0.0 MiB           7           e2_star = tmp2 @ e2_star
   116   4400.2 MiB      0.0 MiB           7           combined_e1.append(e1_star)
   117   4400.2 MiB      0.0 MiB           7           combined_e2.append(e2_star)
   118   4400.2 MiB      0.0 MiB           7           obj += e1_star[nodes1].T @  e2_star[nodes2]
   119   4400.2 MiB      0.0 MiB           1       e = time()
   120                                         
   121                                         
   122   4400.2 MiB      0.0 MiB           1       obj = obj/K_nei
   123   4400.2 MiB      0.0 MiB           1       u, _, v = np.linalg.svd(obj)
   124   4400.2 MiB      0.0 MiB           1       R = u @ v
   125   4400.2 MiB      0.0 MiB           1       trans_e1 = e1 @ R
   126                                         
   127   4477.1 MiB     76.9 MiB          11       trans_combined_e1 = np.concatenate([item@ R for item in combined_e1],axis=-1)
   128   4477.1 MiB      0.0 MiB           1       combined_e2 = np.concatenate(combined_e2, axis=-1)
   129                                         
   130   4477.1 MiB      0.0 MiB           1       return trans_e1, e2, trans_combined_e1,combined_e2


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   132   2829.1 MiB   2829.1 MiB           1   @profile
   133                                         def select_train_nodes(e1,e2,train_ratio=0.01,distance_metric="euclidean",num_top=1):
   134                                             ## 稀疏矩阵对齐
   135   2829.1 MiB      0.0 MiB           1       n_nodes = e1.shape[0]
   136                                         
   137   2829.1 MiB      0.0 MiB           1       kd_tree = KDTree(e2, metric=distance_metric)
   138                                         
   139   2829.1 MiB      0.0 MiB           1       dist, ind = kd_tree.query(e1, k=num_top)
   140   2829.1 MiB      0.0 MiB           1       dist_list = -dist[:,0]
   141   2829.1 MiB      0.0 MiB           1       ind_list = ind[:,0]
   142                                         
   143   2829.1 MiB      0.0 MiB           1       index_l = heapq.nlargest(int(train_ratio*n_nodes), range(len(dist_list)), dist_list.__getitem__)
   144   2829.1 MiB      0.0 MiB        4939       train_data_dict = {i: ind_list[i] for i in index_l}
   145                                         
   146                                         
   147   2829.1 MiB      0.0 MiB           1       return train_data_dict


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    78   2829.1 MiB   2829.1 MiB           1   @profile
    79                                         def align_embedding(g1,g2 ,nodes1 ,nodes2,K_nei,r_rate,e1=None,e2=None):
    80   3572.6 MiB    743.5 MiB           1       adj1 = nx.to_numpy_array(g1,nodelist=list(range(len(g1))))
    81   4322.8 MiB    750.2 MiB           1       adj2 = nx.to_numpy_array(g2, nodelist=list(range(len(g2))))
    82   4322.8 MiB      0.0 MiB           1       D1 = np.sum(adj1,axis=0)
    83   4322.8 MiB      0.0 MiB           1       D2 = np.sum(adj2,axis=0)
    84   4322.8 MiB      0.0 MiB           1       dim=128
    85   4322.8 MiB      0.0 MiB           1       if(len(g1)<dim):
    86                                                 dim=len(g1)-1
    87   4322.8 MiB      0.0 MiB           1       if(len(g2)<dim):
    88                                                 dim=len(g2)-1
    89                                             #path1 = r"dataset/{}/Embedding_G1_{}.npy".format(dataname,str(r_rate))
    90                                             #path2 = r"dataset/{}/Embedding_G2_{}.npy".format(dataname, str(r_rate))
    91                                         
    92   4322.8 MiB      0.0 MiB           1       if e1 is None:
    93                                                 if False:#os.path.exists(path1):
    94                                                     e1 = np.load(path1)
    95                                                     e2 = np.load(path2)
    96                                                 else:
    97                                                     e1 = netmf(sps.csr_matrix(adj1),dim)
    98                                                     e2 = netmf(sps.csr_matrix(adj2),dim)
    99                                         
   100                                         
   101                                         
   102   4322.8 MiB      0.0 MiB           1       obj = e1[nodes1].T @  e2[nodes2]
   103   4322.8 MiB      0.0 MiB           1       e1_star = e1
   104   4322.8 MiB      0.0 MiB           1       e2_star = e2
   105                                         
   106   4322.8 MiB      0.0 MiB           1       combined_e1 = [e1]
   107   4322.8 MiB      0.0 MiB           1       combined_e2 = [e2]
   108                                         
   109   4322.8 MiB      0.0 MiB           1       tmp1 = sparse.csr_matrix(np.diag(1 / D1))@sparse.csr_matrix(adj1)
   110   4322.8 MiB      0.0 MiB           1       tmp2 = sparse.csr_matrix(np.diag(1 / D2))@sparse.csr_matrix(adj2)
   111                                         
   112   4322.8 MiB      0.0 MiB           1       s = time()
   113   4322.8 MiB      0.0 MiB           8       for i in range(K_nei):
   114   4322.8 MiB      0.0 MiB           7           e1_star = tmp1 @ e1_star
   115   4322.8 MiB      0.0 MiB           7           e2_star = tmp2 @ e2_star
   116   4322.8 MiB      0.0 MiB           7           combined_e1.append(e1_star)
   117   4322.8 MiB      0.0 MiB           7           combined_e2.append(e2_star)
   118   4322.8 MiB      0.0 MiB           7           obj += e1_star[nodes1].T @  e2_star[nodes2]
   119   4322.8 MiB      0.0 MiB           1       e = time()
   120                                         
   121                                         
   122   4322.8 MiB      0.0 MiB           1       obj = obj/K_nei
   123   4322.8 MiB      0.0 MiB           1       u, _, v = np.linalg.svd(obj)
   124   4322.8 MiB      0.0 MiB           1       R = u @ v
   125   4322.8 MiB      0.0 MiB           1       trans_e1 = e1 @ R
   126                                         
   127   4399.9 MiB     77.1 MiB          11       trans_combined_e1 = np.concatenate([item@ R for item in combined_e1],axis=-1)
   128   4477.3 MiB     77.5 MiB           1       combined_e2 = np.concatenate(combined_e2, axis=-1)
   129                                         
   130   4477.3 MiB      0.0 MiB           1       return trans_e1, e2, trans_combined_e1,combined_e2


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   132   2906.5 MiB   2906.5 MiB           1   @profile
   133                                         def select_train_nodes(e1,e2,train_ratio=0.01,distance_metric="euclidean",num_top=1):
   134                                             ## 稀疏矩阵对齐
   135   2906.5 MiB      0.0 MiB           1       n_nodes = e1.shape[0]
   136                                         
   137   2906.5 MiB      0.0 MiB           1       kd_tree = KDTree(e2, metric=distance_metric)
   138                                         
   139   2906.5 MiB      0.0 MiB           1       dist, ind = kd_tree.query(e1, k=num_top)
   140   2906.5 MiB      0.0 MiB           1       dist_list = -dist[:,0]
   141   2906.5 MiB      0.0 MiB           1       ind_list = ind[:,0]
   142                                         
   143   2906.5 MiB      0.0 MiB           1       index_l = heapq.nlargest(int(train_ratio*n_nodes), range(len(dist_list)), dist_list.__getitem__)
   144   2906.5 MiB      0.0 MiB        4939       train_data_dict = {i: ind_list[i] for i in index_l}
   145                                         
   146                                         
   147   2906.5 MiB      0.0 MiB           1       return train_data_dict


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    78   2906.5 MiB   2906.5 MiB           1   @profile
    79                                         def align_embedding(g1,g2 ,nodes1 ,nodes2,K_nei,r_rate,e1=None,e2=None):
    80   3650.0 MiB    743.5 MiB           1       adj1 = nx.to_numpy_array(g1,nodelist=list(range(len(g1))))
    81   4400.2 MiB    750.2 MiB           1       adj2 = nx.to_numpy_array(g2, nodelist=list(range(len(g2))))
    82   4400.2 MiB      0.0 MiB           1       D1 = np.sum(adj1,axis=0)
    83   4400.2 MiB      0.0 MiB           1       D2 = np.sum(adj2,axis=0)
    84   4400.2 MiB      0.0 MiB           1       dim=128
    85   4400.2 MiB      0.0 MiB           1       if(len(g1)<dim):
    86                                                 dim=len(g1)-1
    87   4400.2 MiB      0.0 MiB           1       if(len(g2)<dim):
    88                                                 dim=len(g2)-1
    89                                             #path1 = r"dataset/{}/Embedding_G1_{}.npy".format(dataname,str(r_rate))
    90                                             #path2 = r"dataset/{}/Embedding_G2_{}.npy".format(dataname, str(r_rate))
    91                                         
    92   4400.2 MiB      0.0 MiB           1       if e1 is None:
    93                                                 if False:#os.path.exists(path1):
    94                                                     e1 = np.load(path1)
    95                                                     e2 = np.load(path2)
    96                                                 else:
    97                                                     e1 = netmf(sps.csr_matrix(adj1),dim)
    98                                                     e2 = netmf(sps.csr_matrix(adj2),dim)
    99                                         
   100                                         
   101                                         
   102   4400.2 MiB      0.0 MiB           1       obj = e1[nodes1].T @  e2[nodes2]
   103   4400.2 MiB      0.0 MiB           1       e1_star = e1
   104   4400.2 MiB      0.0 MiB           1       e2_star = e2
   105                                         
   106   4400.2 MiB      0.0 MiB           1       combined_e1 = [e1]
   107   4400.2 MiB      0.0 MiB           1       combined_e2 = [e2]
   108                                         
   109   4400.2 MiB      0.0 MiB           1       tmp1 = sparse.csr_matrix(np.diag(1 / D1))@sparse.csr_matrix(adj1)
   110   4400.2 MiB      0.0 MiB           1       tmp2 = sparse.csr_matrix(np.diag(1 / D2))@sparse.csr_matrix(adj2)
   111                                         
   112   4400.2 MiB      0.0 MiB           1       s = time()
   113   4400.2 MiB      0.0 MiB           8       for i in range(K_nei):
   114   4400.2 MiB      0.0 MiB           7           e1_star = tmp1 @ e1_star
   115   4400.2 MiB      0.0 MiB           7           e2_star = tmp2 @ e2_star
   116   4400.2 MiB      0.0 MiB           7           combined_e1.append(e1_star)
   117   4400.2 MiB      0.0 MiB           7           combined_e2.append(e2_star)
   118   4400.2 MiB      0.0 MiB           7           obj += e1_star[nodes1].T @  e2_star[nodes2]
   119   4400.2 MiB      0.0 MiB           1       e = time()
   120                                         
   121                                         
   122   4400.2 MiB      0.0 MiB           1       obj = obj/K_nei
   123   4400.2 MiB      0.0 MiB           1       u, _, v = np.linalg.svd(obj)
   124   4400.3 MiB      0.1 MiB           1       R = u @ v
   125   4400.3 MiB      0.0 MiB           1       trans_e1 = e1 @ R
   126                                         
   127   4477.3 MiB     77.0 MiB          11       trans_combined_e1 = np.concatenate([item@ R for item in combined_e1],axis=-1)
   128   4477.3 MiB      0.0 MiB           1       combined_e2 = np.concatenate(combined_e2, axis=-1)
   129                                         
   130   4477.3 MiB      0.0 MiB           1       return trans_e1, e2, trans_combined_e1,combined_e2


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   132   2829.1 MiB   2829.1 MiB           1   @profile
   133                                         def select_train_nodes(e1,e2,train_ratio=0.01,distance_metric="euclidean",num_top=1):
   134                                             ## 稀疏矩阵对齐
   135   2829.1 MiB      0.0 MiB           1       n_nodes = e1.shape[0]
   136                                         
   137   2829.1 MiB      0.0 MiB           1       kd_tree = KDTree(e2, metric=distance_metric)
   138                                         
   139   2829.1 MiB      0.0 MiB           1       dist, ind = kd_tree.query(e1, k=num_top)
   140   2829.1 MiB      0.0 MiB           1       dist_list = -dist[:,0]
   141   2829.1 MiB      0.0 MiB           1       ind_list = ind[:,0]
   142                                         
   143   2829.1 MiB      0.0 MiB           1       index_l = heapq.nlargest(int(train_ratio*n_nodes), range(len(dist_list)), dist_list.__getitem__)
   144   2829.1 MiB      0.0 MiB        4939       train_data_dict = {i: ind_list[i] for i in index_l}
   145                                         
   146                                         
   147   2829.1 MiB      0.0 MiB           1       return train_data_dict


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    78   2829.1 MiB   2829.1 MiB           1   @profile
    79                                         def align_embedding(g1,g2 ,nodes1 ,nodes2,K_nei,r_rate,e1=None,e2=None):
    80   3572.7 MiB    743.5 MiB           1       adj1 = nx.to_numpy_array(g1,nodelist=list(range(len(g1))))
    81   4322.8 MiB    750.2 MiB           1       adj2 = nx.to_numpy_array(g2, nodelist=list(range(len(g2))))
    82   4322.8 MiB      0.0 MiB           1       D1 = np.sum(adj1,axis=0)
    83   4322.8 MiB      0.0 MiB           1       D2 = np.sum(adj2,axis=0)
    84   4322.8 MiB      0.0 MiB           1       dim=128
    85   4322.8 MiB      0.0 MiB           1       if(len(g1)<dim):
    86                                                 dim=len(g1)-1
    87   4322.8 MiB      0.0 MiB           1       if(len(g2)<dim):
    88                                                 dim=len(g2)-1
    89                                             #path1 = r"dataset/{}/Embedding_G1_{}.npy".format(dataname,str(r_rate))
    90                                             #path2 = r"dataset/{}/Embedding_G2_{}.npy".format(dataname, str(r_rate))
    91                                         
    92   4322.8 MiB      0.0 MiB           1       if e1 is None:
    93                                                 if False:#os.path.exists(path1):
    94                                                     e1 = np.load(path1)
    95                                                     e2 = np.load(path2)
    96                                                 else:
    97                                                     e1 = netmf(sps.csr_matrix(adj1),dim)
    98                                                     e2 = netmf(sps.csr_matrix(adj2),dim)
    99                                         
   100                                         
   101                                         
   102   4322.8 MiB      0.0 MiB           1       obj = e1[nodes1].T @  e2[nodes2]
   103   4322.8 MiB      0.0 MiB           1       e1_star = e1
   104   4322.8 MiB      0.0 MiB           1       e2_star = e2
   105                                         
   106   4322.8 MiB      0.0 MiB           1       combined_e1 = [e1]
   107   4322.8 MiB      0.0 MiB           1       combined_e2 = [e2]
   108                                         
   109   4322.8 MiB      0.0 MiB           1       tmp1 = sparse.csr_matrix(np.diag(1 / D1))@sparse.csr_matrix(adj1)
   110   4322.8 MiB      0.0 MiB           1       tmp2 = sparse.csr_matrix(np.diag(1 / D2))@sparse.csr_matrix(adj2)
   111                                         
   112   4322.8 MiB      0.0 MiB           1       s = time()
   113   4322.8 MiB      0.0 MiB           8       for i in range(K_nei):
   114   4322.8 MiB      0.0 MiB           7           e1_star = tmp1 @ e1_star
   115   4322.8 MiB      0.0 MiB           7           e2_star = tmp2 @ e2_star
   116   4322.8 MiB      0.0 MiB           7           combined_e1.append(e1_star)
   117   4322.8 MiB      0.0 MiB           7           combined_e2.append(e2_star)
   118   4322.8 MiB      0.0 MiB           7           obj += e1_star[nodes1].T @  e2_star[nodes2]
   119   4322.8 MiB      0.0 MiB           1       e = time()
   120                                         
   121                                         
   122   4322.8 MiB      0.0 MiB           1       obj = obj/K_nei
   123   4322.8 MiB      0.0 MiB           1       u, _, v = np.linalg.svd(obj)
   124   4322.8 MiB      0.0 MiB           1       R = u @ v
   125   4322.8 MiB      0.0 MiB           1       trans_e1 = e1 @ R
   126                                         
   127   4399.8 MiB     76.9 MiB          11       trans_combined_e1 = np.concatenate([item@ R for item in combined_e1],axis=-1)
   128   4477.2 MiB     77.5 MiB           1       combined_e2 = np.concatenate(combined_e2, axis=-1)
   129                                         
   130   4477.2 MiB      0.0 MiB           1       return trans_e1, e2, trans_combined_e1,combined_e2


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   132   2906.4 MiB   2906.4 MiB           1   @profile
   133                                         def select_train_nodes(e1,e2,train_ratio=0.01,distance_metric="euclidean",num_top=1):
   134                                             ## 稀疏矩阵对齐
   135   2906.4 MiB      0.0 MiB           1       n_nodes = e1.shape[0]
   136                                         
   137   2906.4 MiB      0.0 MiB           1       kd_tree = KDTree(e2, metric=distance_metric)
   138                                         
   139   2906.4 MiB      0.0 MiB           1       dist, ind = kd_tree.query(e1, k=num_top)
   140   2906.4 MiB      0.0 MiB           1       dist_list = -dist[:,0]
   141   2906.4 MiB      0.0 MiB           1       ind_list = ind[:,0]
   142                                         
   143   2906.4 MiB      0.0 MiB           1       index_l = heapq.nlargest(int(train_ratio*n_nodes), range(len(dist_list)), dist_list.__getitem__)
   144   2906.4 MiB      0.0 MiB        4939       train_data_dict = {i: ind_list[i] for i in index_l}
   145                                         
   146                                         
   147   2906.4 MiB      0.0 MiB           1       return train_data_dict


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    78   2906.4 MiB   2906.4 MiB           1   @profile
    79                                         def align_embedding(g1,g2 ,nodes1 ,nodes2,K_nei,r_rate,e1=None,e2=None):
    80   3649.9 MiB    743.5 MiB           1       adj1 = nx.to_numpy_array(g1,nodelist=list(range(len(g1))))
    81   4400.1 MiB    750.2 MiB           1       adj2 = nx.to_numpy_array(g2, nodelist=list(range(len(g2))))
    82   4400.1 MiB      0.0 MiB           1       D1 = np.sum(adj1,axis=0)
    83   4400.1 MiB      0.0 MiB           1       D2 = np.sum(adj2,axis=0)
    84   4400.1 MiB      0.0 MiB           1       dim=128
    85   4400.1 MiB      0.0 MiB           1       if(len(g1)<dim):
    86                                                 dim=len(g1)-1
    87   4400.1 MiB      0.0 MiB           1       if(len(g2)<dim):
    88                                                 dim=len(g2)-1
    89                                             #path1 = r"dataset/{}/Embedding_G1_{}.npy".format(dataname,str(r_rate))
    90                                             #path2 = r"dataset/{}/Embedding_G2_{}.npy".format(dataname, str(r_rate))
    91                                         
    92   4400.1 MiB      0.0 MiB           1       if e1 is None:
    93                                                 if False:#os.path.exists(path1):
    94                                                     e1 = np.load(path1)
    95                                                     e2 = np.load(path2)
    96                                                 else:
    97                                                     e1 = netmf(sps.csr_matrix(adj1),dim)
    98                                                     e2 = netmf(sps.csr_matrix(adj2),dim)
    99                                         
   100                                         
   101                                         
   102   4400.1 MiB      0.0 MiB           1       obj = e1[nodes1].T @  e2[nodes2]
   103   4400.1 MiB      0.0 MiB           1       e1_star = e1
   104   4400.1 MiB      0.0 MiB           1       e2_star = e2
   105                                         
   106   4400.1 MiB      0.0 MiB           1       combined_e1 = [e1]
   107   4400.1 MiB      0.0 MiB           1       combined_e2 = [e2]
   108                                         
   109   4400.1 MiB      0.0 MiB           1       tmp1 = sparse.csr_matrix(np.diag(1 / D1))@sparse.csr_matrix(adj1)
   110   4400.1 MiB      0.0 MiB           1       tmp2 = sparse.csr_matrix(np.diag(1 / D2))@sparse.csr_matrix(adj2)
   111                                         
   112   4400.1 MiB      0.0 MiB           1       s = time()
   113   4400.1 MiB      0.0 MiB           8       for i in range(K_nei):
   114   4400.1 MiB      0.0 MiB           7           e1_star = tmp1 @ e1_star
   115   4400.1 MiB      0.0 MiB           7           e2_star = tmp2 @ e2_star
   116   4400.1 MiB      0.0 MiB           7           combined_e1.append(e1_star)
   117   4400.1 MiB      0.0 MiB           7           combined_e2.append(e2_star)
   118   4400.1 MiB      0.0 MiB           7           obj += e1_star[nodes1].T @  e2_star[nodes2]
   119   4400.1 MiB      0.0 MiB           1       e = time()
   120                                         
   121                                         
   122   4400.1 MiB      0.0 MiB           1       obj = obj/K_nei
   123   4400.1 MiB      0.0 MiB           1       u, _, v = np.linalg.svd(obj)
   124   4400.1 MiB      0.0 MiB           1       R = u @ v
   125   4400.1 MiB      0.0 MiB           1       trans_e1 = e1 @ R
   126                                         
   127   4477.1 MiB     77.0 MiB          11       trans_combined_e1 = np.concatenate([item@ R for item in combined_e1],axis=-1)
   128   4477.1 MiB      0.0 MiB           1       combined_e2 = np.concatenate(combined_e2, axis=-1)
   129                                         
   130   4477.1 MiB      0.0 MiB           1       return trans_e1, e2, trans_combined_e1,combined_e2


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   132   2828.9 MiB   2828.9 MiB           1   @profile
   133                                         def select_train_nodes(e1,e2,train_ratio=0.01,distance_metric="euclidean",num_top=1):
   134                                             ## 稀疏矩阵对齐
   135   2828.9 MiB      0.0 MiB           1       n_nodes = e1.shape[0]
   136                                         
   137   2828.9 MiB      0.0 MiB           1       kd_tree = KDTree(e2, metric=distance_metric)
   138                                         
   139   2828.9 MiB      0.0 MiB           1       dist, ind = kd_tree.query(e1, k=num_top)
   140   2828.9 MiB      0.0 MiB           1       dist_list = -dist[:,0]
   141   2828.9 MiB      0.0 MiB           1       ind_list = ind[:,0]
   142                                         
   143   2828.9 MiB      0.0 MiB           1       index_l = heapq.nlargest(int(train_ratio*n_nodes), range(len(dist_list)), dist_list.__getitem__)
   144   2828.9 MiB      0.0 MiB        4939       train_data_dict = {i: ind_list[i] for i in index_l}
   145                                         
   146                                         
   147   2828.9 MiB      0.0 MiB           1       return train_data_dict


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    29   2828.9 MiB   2828.9 MiB           1   @profile
    30                                         def convertToPermHungarian2(row_ind,col_ind, n, m):
    31   2828.9 MiB      0.0 MiB           1       P= np.zeros((n,m))
    32   2828.9 MiB      0.0 MiB           1       ans = []
    33                                             #print(len(row_ind),len(col_ind),n,m)
    34   2867.3 MiB      0.3 MiB        9873       for i in range(n):
    35   2867.3 MiB     37.6 MiB        9872           P[row_ind[i]][col_ind[i]] = 1
    36                                                 #print(row_ind[i],col_ind[i])
    37   2867.3 MiB      0.0 MiB        9872           if (row_ind[i] >= n) or (col_ind[i] >= m):
    38                                                     continue
    39   2867.3 MiB      0.5 MiB        9872           ans.append((row_ind[i], col_ind[i]))
    40   2867.3 MiB      0.0 MiB           1       return P, ans


Filename: /home/konstantinos/Alpine/mcmc/mmnc_run.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   244    609.5 MiB    609.5 MiB           1   @profile
   245                                         def run_immnc_align(g1,g2,ans_dict,K_de=3,K_nei=3,
   246                                                             metric=[],train_ratio=0.04,niters=10,
   247                                                             rate=0.01,r_rate=0,fast=False):
   248                                             #path1 = r"dataset/{}/{}_G1_degree_feature.npy".format(dataname, dataname)
   249                                             #path2 = r"dataset/{}/{}_G2_degree_feature.npy".format(dataname, dataname)
   250   1356.4 MiB    746.9 MiB           1       A = nx.to_numpy_array(g1)
   251   2106.9 MiB    750.5 MiB           1       B = nx.to_numpy_array(g2)
   252                                             if False:#os.path.exists(path1):
   253                                                 embed1 = np.load(path1)
   254                                                 embed2 = np.load(path2)
   255                                             else:
   256   2414.0 MiB    307.1 MiB           1           embed1 = CenaExtractNodeFeature(g1, K_de)
   257   2511.0 MiB     97.0 MiB           1           embed2 = CenaExtractNodeFeature(g2, K_de)
   258                                                 #np.save(path1, embed1)
   259                                                 #np.save(path2, embed2)
   260                                         
   261                                         
   262                                             # train_dict = select_train_nodes(embed1, embed2, train_ratio=train_ratio)
   263   2511.0 MiB      0.1 MiB           1       train_dict = fast_select_train_nodes(g1,g2,embed1,embed2,train_ratio=train_ratio,degree_threshold=degree_thresold )
   264   2511.0 MiB      0.0 MiB           1       nodes1 = list(train_dict.keys())
   265   2511.0 MiB      0.0 MiB         397       nodes2 = list([train_dict[i] for i in nodes1])
   266   2926.1 MiB   -543.8 MiB          11       for i in range(niters):
   267                                                 # Step 2: Align Embedding Spaces
   268   2926.1 MiB   -446.6 MiB          10           if i==0:
   269   2977.8 MiB    466.8 MiB           1               aligned_embed1, embed2,trans_combined_e1,combined_e2 = align_embedding(g1, g2, nodes1,nodes2,K_nei,r_rate)
   270                                         
   271                                                 else:
   272   2926.1 MiB   -990.4 MiB          18               aligned_embed1, embed2, trans_combined_e1, combined_e2 = align_embedding(g1, g2, nodes1,
   273   2926.1 MiB   -446.6 MiB           9                                                                                    nodes2, K_nei,r_rate,aligned_embed1,embed2)
   274                                         
   275                                                 # Step 3: Match Nodes with Similar Embeddings
   276   2977.8 MiB   -543.8 MiB          10           if fast:
   277                                                     train_dict = fast_select_train_nodes(g1, g2, trans_combined_e1, combined_e2,
   278                                                                                          train_ratio=max(train_ratio + rate * (i + 1), 1.0),
   279                                                                                          degree_threshold=degree_thresold)
   280                                                 else:
   281   2926.1 MiB  -1061.4 MiB          10               train_dict = select_train_nodes(trans_combined_e1, combined_e2, train_ratio=max(train_ratio+rate*(i+1),0.5))
   282                                         
   283                                         
   284   2926.1 MiB   -543.8 MiB          10           nodes1 = list(train_dict.keys())
   285   2926.1 MiB -2685581.2 MiB       49390           nodes2 = list([train_dict[i] for i in nodes1])
   286                                             
   287   2828.9 MiB    -97.1 MiB           1       list_of_nodes = []
   288   2828.9 MiB      0.0 MiB           1       if "hits1" in metric:
   289   2828.9 MiB      0.0 MiB           1           Acc, train_data_dict = KDTreeAlignmentHit1new(aligned_embed1, embed2, ans_dict)
   290                                                 #print("iMMNC, acc_hits@1:{}".format(Acc))
   291   2828.9 MiB      0.0 MiB        9873           for i in range(len(g1.nodes)):
   292   2828.9 MiB      0.0 MiB        9872               list_of_nodes.append(train_data_dict[i])
   293                                                 #print(list_of_nodes)
   294   2828.9 MiB      0.0 MiB           1       list_of_nodes2_sorted=[]
   295                                             #print(len(g1.nodes))
   296   2828.9 MiB      0.0 MiB        9873       for i in range(len(g1.nodes)):
   297   2828.9 MiB      0.0 MiB        9872           list_of_nodes2_sorted.append(i)
   298                                             #for i in range
   299   2828.9 MiB      0.0 MiB           1       m=len(list_of_nodes)
   300   2828.9 MiB      0.0 MiB           1       n=len(g2.nodes)
   301   2828.9 MiB      0.0 MiB           1       n1=max(m,n)
   302   2828.9 MiB      0.0 MiB           1       n2=min(m,n)
   303   2828.9 MiB      0.0 MiB           1       copy_list_of_nodes=list_of_nodes.copy()
   304                                             #P2=convertToPermHungarianmc(list_of_nodes2_sorted,copy_list_of_nodes,n2,n1)
   305   2867.3 MiB     38.4 MiB           1       P2,_=convertToPermHungarian2(list_of_nodes2_sorted,copy_list_of_nodes,n2,n1)
   306                                             #print(list_of_nodes2_sorted)
   307                                         
   308   2896.3 MiB     28.9 MiB           1       forbnorm = LA.norm(A[:n2,:n2] - (P2@B@P2.T)[:n2,:n2], 'fro')**2 
   309   2896.3 MiB      0.0 MiB           1       return list_of_nodes,forbnorm


Filename: /home/konstantinos/Alpine/mcmc/mc.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   100    608.7 MiB    608.7 MiB           1   @profile
   101                                         def mcAlign(G1, G2,Q_real):
   102    608.7 MiB      0.0 MiB           1       train_ratio = 0.04
   103    608.7 MiB      0.0 MiB           1       K_de = 3
   104    608.7 MiB      0.0 MiB           1       K_nei = 7
   105    608.7 MiB      0.0 MiB           1       T = 10
   106    608.7 MiB      0.0 MiB           1       fast_select = False
   107    608.7 MiB      0.0 MiB           1       np.random.seed(0)
   108    608.7 MiB      0.0 MiB           1       ans_dict = {}
   109    609.5 MiB      0.9 MiB        9873       for i in range(len(Q_real)): ans_dict[i] = Q_real[i]
   110                                             if True:
   111    609.5 MiB      0.0 MiB           1           metrics = ["hits1"]
   112    609.5 MiB      0.0 MiB           1           fast_select = False
   113                                         
   114   1103.2 MiB    493.6 MiB           2           list_of_nodes,frob = run_immnc_align(G1,G2,ans_dict,
   115    609.5 MiB      0.0 MiB           1                           train_ratio=train_ratio,
   116    609.5 MiB      0.0 MiB           1                           K_de=K_de,
   117    609.5 MiB      0.0 MiB           1                           niters=T,
   118    609.5 MiB      0.0 MiB           1                           rate=train_ratio*0.5,
   119    609.5 MiB      0.0 MiB           1                           K_nei=K_nei,
   120    609.5 MiB      0.0 MiB           1                           r_rate=0,
   121    609.5 MiB      0.0 MiB           1                           metric=metrics,
   122    609.5 MiB      0.0 MiB           1                           fast=fast_select)
   123                                                     #print(list_of_nodes)
   124                                                 #accuracy = np.sum(np.array(Q_real)==np.array(list_of_nodes))/len(Q_real)
   125                                                 #print(f'My accuracy is {accuracy}.')
   126                                                 #print(f'My frob is {frob}.')
   127                                                 #print(len(list_of_nodes))
   128   1103.2 MiB      0.0 MiB           1           return list_of_nodes,frob


----  mcmc ----
----> Forb_norm: 256851.99999999997
----> Accuracy: 0.11304347826086956
----> Spec_norm: 0
----> Time: 1930.4506669044495
----> Isomorphic: False






Filename: PartialTest.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    28    385.7 MiB    385.7 MiB           1   @profile
    29                                         def RunExp():
    30    385.7 MiB      0.0 MiB           1       plotall = False
    31                                         
    32    385.7 MiB      0.0 MiB           1       folderall = 'data3_'
    33                                         
    34                                         
    35    385.7 MiB      0.0 MiB           1       foldernames = [ 'arenas','netscience', 'multimanga', 'highschool', 'voles']
    36    385.7 MiB      0.0 MiB           1       n_G = [ 1133,379, 1004, 327, 712]
    37                                             #foldernames = [  'douban']
    38                                             #n_G = [  3906]
    39    385.7 MiB      0.0 MiB           1       foldernames = [ 'netscience']
    40    385.7 MiB      0.0 MiB           1       n_G = [ 379]
    41                                             #foldernames=["random/subgraph_DG_80","random/subgraph_DG_160","random/subgraph_DG_320","random/subgraph_DG_640","random/subgraph_DG_1280","random/subgraph_DG_2560","random/subgraph_DG_5120"]
    42                                             #foldernames1=["random/subgraph_QG_80","random/subgraph_QG_160","random/subgraph_DG_QG","random/subgraph_QG_640","random/subgraph_QG_1280","random/subgraph_QG_2560","random/subgraph_QG_5120"]
    43                                             #n_G = [ 80,160,320,640,1280,2560,5120]
    44                                             #foldernames=["random/subgraph_DG_5120"]
    45                                             #foldernames1=["random/subgraph_QG_5120"]
    46                                             #n_G = [5120]
    47                                             #foldernames = [ 'highschool']
    48                                             #n_G = [ 327]
    49                                             #foldernames = [  'highschool']
    50                                             #n_G = [ 327]
    51                                             #n_G = [575,5002,11586]
    52                                             #n_GQ = [453,4623,8325]
    53                                             #n_GT = [437,4483,7555]
    54                                         
    55                                             #foldernames = [ 'male','route','sp']
    56                                             #n_G = [575]
    57                                             #n_G=[5003]
    58                                             #foldernames = ['facebook']
    59                                             #9916
    60                                             #9871
    61    385.7 MiB      0.0 MiB           1       iters =1
    62    385.7 MiB      0.0 MiB          12       percs = [(i+1)/10 for i in range(0,9)]
    63    385.7 MiB      0.0 MiB           1       percs=[0.1]
    64                                             #tun=[1,2,3,4,5,6,7]
    65    385.7 MiB      0.0 MiB           1       tuns=["Alpine","Cone","SGWL","Alpine_Dummy","Grampa","Regal","Fugal","mcmc","GradP"]
    66    385.7 MiB      0.0 MiB           1       tun=[1,2,3,4,5,6,8,9,10]
    67    385.7 MiB      0.0 MiB           1       tuns=["mcmc"]
    68    385.7 MiB      0.0 MiB           1       tun=[9]
    69                                             #tuns=["Alpine_Dummy","Grad","mcmc"]
    70                                         
    71                                         
    72                                             #tun = [1,8,10]
    73                                             #nL=["_Noise5","_Noise10","_Noise15","_Noise20","_Noise25"]
    74                                             #tuns=["Alpine"]
    75                                             #tun=[4,8]
    76                                         
    77                                             #tun = [1]
    78                                             #n_G = [4039]
    79                                             #n_GQ = [9872]
    80                                             #n_GT = [9872]
    81                                         
    82                                             #n_G = [1043]
    83                                             #n_GQ = [1000]
    84                                             #n_GT = [1000]
    85                                         
    86                                             #foldernames = ['sp']
    87    385.7 MiB      0.0 MiB           1       foldernames = [ 'dblp']
    88    385.7 MiB      0.0 MiB           1       n_G = [9916]
    89    982.4 MiB      0.0 MiB           2       def printR(name,forb_norm,accuracy,spec_norm,time_diff,isomorphic=False):
    90    982.4 MiB      0.0 MiB           1           print('---- ',name, '----')
    91    982.4 MiB      0.0 MiB           1           print('----> Forb_norm:', forb_norm)
    92    982.4 MiB      0.0 MiB           1           print('----> Accuracy:', accuracy)
    93    982.4 MiB      0.0 MiB           1           print('----> Spec_norm:', spec_norm)
    94    982.4 MiB      0.0 MiB           1           print('----> Time:', time_diff)
    95    982.4 MiB      0.0 MiB           1           print('----> Isomorphic:', isomorphic)
    96    982.4 MiB      0.0 MiB           1           print()     
    97                                         
    98    385.7 MiB      0.0 MiB           1       experimental_folder=f'./{folderall}/res/'
    99    385.8 MiB      0.1 MiB           1       new_id = generate_new_id(get_max_previous_id(experimental_folder))
   100    385.8 MiB      0.0 MiB           1       experimental_folder=f'./{folderall}/res/_{new_id}/'   
   101    385.8 MiB      0.0 MiB           1       DGS=0
   102    385.8 MiB      0.0 MiB           1       DGES=0
   103    385.8 MiB      0.0 MiB           1       QGS=0
   104    385.8 MiB      0.0 MiB           1       QGES=0
   105    385.8 MiB      0.0 MiB           1       PGS=0
   106    385.8 MiB      0.0 MiB           1       PGES=0         
   107    982.4 MiB      0.0 MiB           2       for k in range(0,len(foldernames)):
   108    406.9 MiB     21.1 MiB           1               G = read_real_graph(n = n_G[k], name_ = f'./raw_data/{foldernames[k]}.txt')
   109    406.9 MiB      0.0 MiB           1               print(G)
   110    406.9 MiB      0.0 MiB           1               DGS=G.number_of_nodes()
   111                                         
   112                                             # Get the number of edges
   113    406.9 MiB      0.0 MiB           1               DGES = G.number_of_edges()
   114                                                     
   115                                                     #perc=percs[0]
   116    982.4 MiB      0.0 MiB           2               for perc in percs: 
   117    982.4 MiB      0.0 MiB           2                   for ptun in range(len(tun)): 
   118    406.9 MiB      0.0 MiB           1                       folder = f'./{folderall}/{foldernames[k]}/{int(perc*100)}'
   119    406.9 MiB      0.0 MiB           1                       os.makedirs(f'{experimental_folder}{foldernames[k]}/{int(perc*100)}', exist_ok=True)
   120    406.9 MiB      0.0 MiB           1                       folder1=f'./{experimental_folder}/{foldernames[k]}/{int(perc*100)}'
   121    406.9 MiB      0.0 MiB           1                       file_A_results = open(f'{folder1}/SizeTest_results{tuns[ptun]}.txt', 'w')
   122    406.9 MiB      0.0 MiB           1                       file_A_results.write(f'DGS DGES QGS QGES PGS PGES forb_norm accuracy spec_norm time isomorphic \n')
   123                                                             
   124    406.9 MiB      0.0 MiB           1                       file_real_spectrum = open(f'{folder1}/real_Tspectrum{tuns[ptun]}.txt', 'w')
   125    406.9 MiB      0.0 MiB           1                       file_A_spectrum = open(f'{folder1}/A_Tspectrum{tuns[ptun]}.txt', 'w')
   126    406.9 MiB      0.0 MiB           1                       n_Q = int(perc*G.number_of_nodes())
   127                                                             #n_Q=n_GQ[k]#9872
   128    406.9 MiB      0.0 MiB           1                       n_Q = 9872 
   129    406.9 MiB      0.0 MiB           1                       print(f'Size of subgraph: {n_Q}')
   130    982.4 MiB      0.0 MiB           2                       for iter in range(iters):
   131    406.9 MiB      0.0 MiB           1                           folder_ = f'{folder}/{iter}'
   132    406.9 MiB      0.0 MiB           1                           folder1_ = f'{folder1}/{iter}'
   133                                                                 #folder_ = f'{folder}'
   134    406.9 MiB      0.0 MiB           1                           os.makedirs(f'{folder1_}', exist_ok=True)
   135    406.9 MiB      0.0 MiB           1                           file_subgraph = f'{folder_}/subgraph.txt'
   136    406.9 MiB      0.0 MiB           1                           file_nodes = f'{folder_}/nodes.txt'
   137                                                                 #file_subgraph = f'raw_data/random/subgraph_QG_{n_G[k]}.txt'
   138                                                                 #file_nodes = f'raw_data/random/nodes_QG_{n_G[k]}.txt'
   139    406.9 MiB      0.0 MiB           1                           Q_real = read_list(file_nodes)
   140    406.9 MiB      0.0 MiB           1                           print(f'Reading subgraph at {file_subgraph}')
   141    406.9 MiB      0.0 MiB           1                           print(f'Reading alignment at {file_nodes}')
   142    425.6 MiB     18.7 MiB           1                           G_Q= read_real_graph(n = n_Q, name_ = file_subgraph)
   143    577.4 MiB    151.8 MiB           1                           A = nx.adjacency_matrix(G_Q).todense()
   144    577.4 MiB      0.0 MiB           1                           print(G_Q)
   145                                                                 #print(Q_real)
   146    577.4 MiB      0.0 MiB           1                           QGS=G_Q.number_of_nodes()
   147    577.4 MiB      0.0 MiB           1                           QGES = G_Q.number_of_edges()
   148                                                                 #L = np.diag(np.array(np.sum(A, axis = 0)))
   149                                                                 #eigv_G_Q, _ = linalg.eig(L - A)
   150                                                                 #idx = eigv_G_Q.argsort()[::]   
   151                                                                 #eigv_G_Q = eigv_G_Q[idx]
   152                                                                 #for el in eigv_G_Q: file_real_spectrum.write(f'{el} ')
   153                                                                 #file_real_spectrum.write(f'\n')
   154    577.4 MiB      0.0 MiB           1                           start = time.time()
   155    577.4 MiB      0.0 MiB           1                           if(tun[ptun]==1):
   156                                                                     print("Alpine")
   157                                                                     _, list_of_nodes, forb_norm = Alpine(G_Q.copy(), G.copy(),mu=1,weight=2)
   158    577.4 MiB      0.0 MiB           1                           elif(tun[ptun]==2):
   159                                                                     print("Cone")
   160                                                                     _, list_of_nodes, forb_norm = coneGAM(G_Q.copy(), G.copy())
   161    577.4 MiB      0.0 MiB           1                           elif(tun[ptun]==3):
   162                                                                     print("SGWL")
   163                                                                     _, list_of_nodes, forb_norm = SGWLSA(G_Q.copy(), G.copy())
   164    577.4 MiB      0.0 MiB           1                           elif(tun[ptun]==4):
   165                                                                     print("Alpine_Dummy")
   166                                                                     _, list_of_nodes, forb_norm = align_new(G_Q.copy(), G.copy(),mu=1,weight=1)
   167    577.4 MiB      0.0 MiB           1                           elif(tun[ptun]==5):
   168                                                                     print("Grampa")
   169                                                                     _, list_of_nodes, forb_norm = Grampa(G_Q.copy(), G.copy())
   170    577.4 MiB      0.0 MiB           1                           elif(tun[ptun]==6):
   171                                                                     print("Regal")
   172                                                                     _, list_of_nodes, forb_norm = Regal(G_Q.copy(), G.copy())      
   173    577.4 MiB      0.0 MiB           1                           elif(tun[ptun]==7):
   174                                                                     print("MDS")
   175                                                                     _, list_of_nodes, forb_norm = MDSGA(G_Q.copy(), G.copy())
   176    577.4 MiB      0.0 MiB           1                           elif(tun[ptun]==8):
   177                                                                     print("fugal")
   178                                                                     _,list_of_nodes, forb_norm = Fugal(G_Q.copy(), G.copy())
   179    577.4 MiB      0.0 MiB           1                           elif(tun[ptun]==9):
   180    577.4 MiB      0.0 MiB           1                               print("mcmc")
   181   1103.2 MiB    525.7 MiB           1                               list_of_nodes, forb_norm = mcAlign(G_Q.copy(), G.copy(),Q_real)
   182                                                                 elif(tun[ptun]==10):
   183                                                                     print("GradAlignP")
   184                                                                     list_of_nodes, forb_norm = gradPMain(G_Q.copy(), G.copy())
   185                                                                 else:
   186                                                                     print("NO given algorithm ID")
   187                                                                     exit()
   188   1103.2 MiB      0.0 MiB           1                           end = time.time()
   189   1103.2 MiB      0.0 MiB           1                           subgraph = G.subgraph(list_of_nodes)
   190                                                                 
   191   1103.2 MiB      0.0 MiB           1                           PGS=subgraph.number_of_nodes()
   192   1103.2 MiB      0.0 MiB           1                           PGES = subgraph.number_of_edges()
   193   1103.2 MiB      0.0 MiB           1                           isomorphic=False
   194   1103.2 MiB      0.0 MiB           1                           if(forb_norm==0):
   195                                                                     isomorphic=True
   196   1103.2 MiB      0.0 MiB           1                           time_diff = end - start
   197   1103.2 MiB      0.0 MiB           1                           file_nodes_pred = open(f'{folder1_}/{tuns[ptun]}.txt','w')
   198   1103.2 MiB      0.0 MiB        9873                           for node in list_of_nodes: file_nodes_pred.write(f'{node}\n')
   199    974.2 MiB   -128.9 MiB           1                           A = nx.adjacency_matrix(nx.induced_subgraph(G, list_of_nodes)).todense()
   200    982.4 MiB      8.2 MiB           1                           L = np.diag(np.array(np.sum(A, axis = 0)))
   201                                         
   202                                         
   203                                                                 #   accuracy = np.sum(np.array(Q_real)==np.array(list_of_nodes))/len(Q_real)
   204    982.4 MiB      0.0 MiB           1                           accuracy = np.sum(np.array(Q_real)==np.array(list_of_nodes))/1265
   205                                                                 #len(Q_real)
   206    982.4 MiB      0.0 MiB           1                           spec_norm=0
   207    982.4 MiB      0.0 MiB           1                           file_A_results.write(f'{DGS} {DGES} {QGS} {QGES} {PGS} {PGES} {forb_norm} {accuracy} {spec_norm} {time_diff} {isomorphic}\n')
   208    982.4 MiB      0.0 MiB           1                           printR(tuns[ptun],forb_norm,accuracy,0,time_diff,isomorphic)            
   209    982.4 MiB      0.0 MiB           1                   print('\n')
   210    982.4 MiB      0.0 MiB           1               print('\n\n')


